{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 - Using NLP to play the stock market\n",
    "\n",
    "In this assignment, we'll use everything we've learned to analyze corporate news and pick stocks. Be aware that in this assignment, we're trying to beat the benchmark of random chance (aka better than 50%).\n",
    "\n",
    "This assignment will involve building three models:\n",
    "\n",
    "**1. An RNN based on word inputs**\n",
    "\n",
    "**2. A CNN based on character inputs**\n",
    "\n",
    "**3. A neural net architecture that merges the previous two models**\n",
    "\n",
    "You will apply these models to predicting whether a stock return will be positive or negative in the same day of a news publication.\n",
    "\n",
    "## Your X - Reuters news data\n",
    "\n",
    "Reuters is a news outlet that reports on corporations, among many other things. Stored in the `news_reuters.csv` file is news data listed in columns. The corresponding columns are the `ticker`, `name of company`, `date of publication`, `headline`, `first sentence`, and `news category`.\n",
    "\n",
    "In this assignment it is up to you to decide how to clean this dataset. For instance, many of the first sentences contain a location name showing where the reporting is done. This is largely irrevant information and will probably just make your data noisier. You can also choose to subset on a certain news category, which might enhance your model performance and also limit the size of your data.\n",
    "\n",
    "## Your Y - Stock information from Yahoo! Finance\n",
    "\n",
    "Trading data from Yahoo! Finance was collected and then normalized using the [S&P 500](https://en.wikipedia.org/wiki/S%26P_500_Index). This is stored in the `stockReturns.json` file. \n",
    "\n",
    "In our dataset, the ticker for the S&P is `^GSPC`. Each ticker is compared the S&P and then judged on whether it is outperforming (positive value) or under-performing (negative value) the S&P. Each value is reported on a daily interval from 2004 to now.\n",
    "\n",
    "Below is a diagram of the data in the json file. Note there are three types of data: short: 1 day return, mid: 7 day return, long 28 day return.\n",
    "\n",
    "```\n",
    "          term (short/mid/long)\n",
    "         /         |         \\\n",
    "   ticker A   ticker B   ticker C\n",
    "      /   \\      /   \\      /   \\\n",
    "  date1 date2 date1 date2 date1 date2\n",
    "```\n",
    "\n",
    "You will need to pick a length of time to focus on (day, week, month). You are welcome to train models on each dataset as well.  \n",
    "\n",
    "Transform the return data such that the outcome will be binary:\n",
    "\n",
    "```\n",
    "label[y < 0] = 0\n",
    "label[y >= 0] = 1\n",
    "```\n",
    "\n",
    "Finally, this data needs needs to be joined on the date and ticker - For each date of news publication, we want to join the corresponding corporation's news on its return information. We make the assumption that the day's return will reflect the sentiment of the news, regardless of timing.\n",
    "\n",
    "\n",
    "# Your models - RNN, CNN, and RNN+CNN\n",
    "\n",
    "For your RNN model, it needs to be based on word inputs, embedding the word inputs, encoding them with an RNN layer, and finally a decoding step (such as softmax or some other choice).\n",
    "\n",
    "Your CNN model will be based on characters. For reference on how to do this, look at the CNN class demonstration in the course repository.\n",
    "\n",
    "Finally you will combine the architecture for both of these models, either [merging](https://github.com/ShadyF/cnn-rnn-classifier) using the [Functional API](https://keras.io/getting-started/functional-api-guide/) or [stacking](http://www.aclweb.org/anthology/S17-2134). See the links for reference.\n",
    "\n",
    "For each of these models, you will need to:\n",
    "1. Create a train and test set, retaining the same test set for every model\n",
    "2. Show the architecture for each model, printing it in your python notebook\n",
    "2. Report the peformance according to some metric\n",
    "3. Compare the performance of all of these models in a table (precision and recall)\n",
    "4. Look at your labeling and print out the underlying data compared to the labels - for each model print out 2-3 examples of a good classification and a bad classification. Make an assertion why your model does well or poorly on those outputs.\n",
    "5. For each model, calculate the return from the three most probable positive stock returns. Compare it to the actual return. Print this information in a table.\n",
    "\n",
    "### Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data + Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>news_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110707</td>\n",
       "      <td>Alcoa profit seen higher on aluminum price surge</td>\n",
       "      <td>* Analysts expect profit of 34 cts/shr vs yea...</td>\n",
       "      <td>topStory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110708</td>\n",
       "      <td>Global markets weekahead: Lacking conviction</td>\n",
       "      <td>LONDON Investors are unlikely to gain strong c...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110708</td>\n",
       "      <td>Jobs halt Wall Street rally  investors eye ear...</td>\n",
       "      <td>NEW YORK Stocks fell on Friday as a weak jobs ...</td>\n",
       "      <td>topStory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       company_name  publish_date  \\\n",
       "0     AA  Alcoa Corporation      20110707   \n",
       "1     AA  Alcoa Corporation      20110708   \n",
       "2     AA  Alcoa Corporation      20110708   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Alcoa profit seen higher on aluminum price surge    \n",
       "1      Global markets weekahead: Lacking conviction    \n",
       "2  Jobs halt Wall Street rally  investors eye ear...   \n",
       "\n",
       "                                      first_sentence news_category  \n",
       "0   * Analysts expect profit of 34 cts/shr vs yea...      topStory  \n",
       "1  LONDON Investors are unlikely to gain strong c...        normal  \n",
       "2  NEW YORK Stocks fell on Friday as a weak jobs ...      topStory  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the news data\n",
    "import pandas as pd\n",
    "\n",
    "news = pd.read_csv('news_reuters.csv', header=None, encoding = \"ISO-8859-1\")\n",
    "news.columns = ['ticker', 'company_name', 'publish_date', 'headline', 'first_sentence', 'news_category']\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>news_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110707</td>\n",
       "      <td>alcoa profit seen higher on aluminum price surge</td>\n",
       "      <td>* Analysts expect profit of 34 cts/shr vs yea...</td>\n",
       "      <td>topStory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110708</td>\n",
       "      <td>global markets weekahead: lacking conviction</td>\n",
       "      <td>LONDON Investors are unlikely to gain strong c...</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110708</td>\n",
       "      <td>jobs halt wall street rally  investors eye ear...</td>\n",
       "      <td>NEW YORK Stocks fell on Friday as a weak jobs ...</td>\n",
       "      <td>topStory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       company_name  publish_date  \\\n",
       "0     AA  Alcoa Corporation      20110707   \n",
       "1     AA  Alcoa Corporation      20110708   \n",
       "2     AA  Alcoa Corporation      20110708   \n",
       "\n",
       "                                            headline  \\\n",
       "0  alcoa profit seen higher on aluminum price surge    \n",
       "1      global markets weekahead: lacking conviction    \n",
       "2  jobs halt wall street rally  investors eye ear...   \n",
       "\n",
       "                                      first_sentence news_category  \n",
       "0   * Analysts expect profit of 34 cts/shr vs yea...      topStory  \n",
       "1  LONDON Investors are unlikely to gain strong c...        normal  \n",
       "2  NEW YORK Stocks fell on Friday as a weak jobs ...      topStory  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['headline'] = news['headline'].str.lower()\n",
    "#news['first_sentence'] = news['first_sentence']\n",
    "\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pandas import to_datetime\n",
    "\n",
    "news['date'] = pd.to_datetime(news['publish_date'], format='%Y%m%d') + timedelta(days=1)\n",
    "#modified_date = date + timedelta(days=1)\n",
    "# = [datetime.strptime(x, '%Y%m%d%H') for x in  ]\n",
    "#news['publish_date_formatted'] = datetime.strptime(news['publish_date'],'%Y%m%d')\n",
    "#date = datetime.strptime(news['publish_date'], \"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>news_category</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110707</td>\n",
       "      <td>alcoa profit seen higher on aluminum price surge</td>\n",
       "      <td>* Analysts expect profit of 34 cts/shr vs yea...</td>\n",
       "      <td>topStory</td>\n",
       "      <td>2011-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110708</td>\n",
       "      <td>global markets weekahead: lacking conviction</td>\n",
       "      <td>LONDON Investors are unlikely to gain strong c...</td>\n",
       "      <td>normal</td>\n",
       "      <td>2011-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110708</td>\n",
       "      <td>jobs halt wall street rally  investors eye ear...</td>\n",
       "      <td>NEW YORK Stocks fell on Friday as a weak jobs ...</td>\n",
       "      <td>topStory</td>\n",
       "      <td>2011-07-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       company_name  publish_date  \\\n",
       "0     AA  Alcoa Corporation      20110707   \n",
       "1     AA  Alcoa Corporation      20110708   \n",
       "2     AA  Alcoa Corporation      20110708   \n",
       "\n",
       "                                            headline  \\\n",
       "0  alcoa profit seen higher on aluminum price surge    \n",
       "1      global markets weekahead: lacking conviction    \n",
       "2  jobs halt wall street rally  investors eye ear...   \n",
       "\n",
       "                                      first_sentence news_category       date  \n",
       "0   * Analysts expect profit of 34 cts/shr vs yea...      topStory 2011-07-08  \n",
       "1  LONDON Investors are unlikely to gain strong c...        normal 2011-07-09  \n",
       "2  NEW YORK Stocks fell on Friday as a weak jobs ...      topStory 2011-07-09  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Return JSON file\n",
    "\n",
    "#### following is how i re-format the stock data. Im going to only look at \"short\" stock return for now, so I filted on short. I also transferred it from JSON to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#stock_return = json.loads(stockReturns.json)\n",
    "stock_return = json.load(open('stockReturns.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['short', 'mid', 'long'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_key = stock_return.keys()\n",
    "stock_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_key = ['short']\n",
    "short_stock_return = dict((k, stock_return[k]) for k in short_key if k in stock_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['short'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_stock_return.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "stock_return_norm = json_normalize(short_stock_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['short.AAPL.20040106', 'short.AAPL.20040107', 'short.AAPL.20040108',\n",
       "       'short.AAPL.20040109', 'short.AAPL.20040113', 'short.AAPL.20040114',\n",
       "       'short.AAPL.20040115', 'short.AAPL.20040116', 'short.AAPL.20040121',\n",
       "       'short.AAPL.20040122',\n",
       "       ...\n",
       "       'short.^GSPC.20180405', 'short.^GSPC.20180406', 'short.^GSPC.20180410',\n",
       "       'short.^GSPC.20180411', 'short.^GSPC.20180412', 'short.^GSPC.20180413',\n",
       "       'short.^GSPC.20180417', 'short.^GSPC.20180418', 'short.^GSPC.20180419',\n",
       "       'short.^GSPC.20180420'],\n",
       "      dtype='object', length=908537)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_return_norm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.iteritems of    short.AAPL.20040106  short.AAPL.20040107  short.AAPL.20040108  \\\n",
       "0              -0.0013               0.0162               0.0311   \n",
       "\n",
       "   short.AAPL.20040109  short.AAPL.20040113  short.AAPL.20040114  \\\n",
       "0              -0.0089               0.0226              -0.0083   \n",
       "\n",
       "   short.AAPL.20040115  short.AAPL.20040116  short.AAPL.20040121  \\\n",
       "0               -0.063              -0.0068              -0.0169   \n",
       "\n",
       "   short.AAPL.20040122          ...           short.^GSPC.20180405  \\\n",
       "0              -0.0153          ...                            0.0   \n",
       "\n",
       "   short.^GSPC.20180406  short.^GSPC.20180410  short.^GSPC.20180411  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "\n",
       "   short.^GSPC.20180412  short.^GSPC.20180413  short.^GSPC.20180417  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "\n",
       "   short.^GSPC.20180418  short.^GSPC.20180419  short.^GSPC.20180420  \n",
       "0                   0.0                   0.0                   0.0  \n",
       "\n",
       "[1 rows x 908537 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_return_norm.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('my_file.csv', 'w') as f:\n",
    "    [f.write('{0},{1}\\n'.format(key, value)) for key, value in stock_return_norm.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "my_file = pd.read_csv('my_file.csv', header=None, encoding = \"ISO-8859-1\")\n",
    "my_file2 = my_file[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>short.AAPL.20040106</td>\n",
       "      <td>0   -0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>short.AAPL.20040107</td>\n",
       "      <td>0    0.0162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short.AAPL.20040108</td>\n",
       "      <td>0    0.0311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0            1\n",
       "0  short.AAPL.20040106  0   -0.0013\n",
       "2  short.AAPL.20040107  0    0.0162\n",
       "4  short.AAPL.20040108  0    0.0311"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_file2.to_csv(\"short_stocks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### this is the end of stock data reformatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_type</th>\n",
       "      <th>ticker</th>\n",
       "      <th>stock_date</th>\n",
       "      <th>stock_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040106</td>\n",
       "      <td>-0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040107</td>\n",
       "      <td>0.0162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040108</td>\n",
       "      <td>0.0311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040109</td>\n",
       "      <td>-0.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040113</td>\n",
       "      <td>0.0226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_type ticker  stock_date  stock_return\n",
       "0      short   AAPL    20040106       -0.0013\n",
       "1      short   AAPL    20040107        0.0162\n",
       "2      short   AAPL    20040108        0.0311\n",
       "3      short   AAPL    20040109       -0.0089\n",
       "4      short   AAPL    20040113        0.0226"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock = pd.read_csv('short_stocks.csv', header=None, encoding = \"ISO-8859-1\")\n",
    "stock.columns = ['stock_type', 'ticker', 'stock_date', 'stock_return']\n",
    "stock.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from pandas import to_datetime\n",
    "\n",
    "stock['date'] = pd.to_datetime(stock['stock_date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_type</th>\n",
       "      <th>ticker</th>\n",
       "      <th>stock_date</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040106</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>2004-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040107</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>2004-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040108</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>2004-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040109</td>\n",
       "      <td>-0.0089</td>\n",
       "      <td>2004-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040113</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>2004-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_type ticker  stock_date  stock_return       date\n",
       "0      short   AAPL    20040106       -0.0013 2004-01-06\n",
       "1      short   AAPL    20040107        0.0162 2004-01-07\n",
       "2      short   AAPL    20040108        0.0311 2004-01-08\n",
       "3      short   AAPL    20040109       -0.0089 2004-01-09\n",
       "4      short   AAPL    20040113        0.0226 2004-01-13"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Stock data and News data by date and ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>news_category</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110707</td>\n",
       "      <td>alcoa profit seen higher on aluminum price surge</td>\n",
       "      <td>* Analysts expect profit of 34 cts/shr vs yea...</td>\n",
       "      <td>topStory</td>\n",
       "      <td>2011-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa Corporation</td>\n",
       "      <td>20110708</td>\n",
       "      <td>global markets weekahead: lacking conviction</td>\n",
       "      <td>LONDON Investors are unlikely to gain strong c...</td>\n",
       "      <td>normal</td>\n",
       "      <td>2011-07-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker       company_name  publish_date  \\\n",
       "0     AA  Alcoa Corporation      20110707   \n",
       "1     AA  Alcoa Corporation      20110708   \n",
       "\n",
       "                                            headline  \\\n",
       "0  alcoa profit seen higher on aluminum price surge    \n",
       "1      global markets weekahead: lacking conviction    \n",
       "\n",
       "                                      first_sentence news_category       date  \n",
       "0   * Analysts expect profit of 34 cts/shr vs yea...      topStory 2011-07-08  \n",
       "1  LONDON Investors are unlikely to gain strong c...        normal 2011-07-09  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_type</th>\n",
       "      <th>ticker</th>\n",
       "      <th>stock_date</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040106</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>2004-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>short</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>20040107</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>2004-01-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_type ticker  stock_date  stock_return       date\n",
       "0      short   AAPL    20040106       -0.0013 2004-01-06\n",
       "1      short   AAPL    20040107        0.0162 2004-01-07"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.merge(news, stock, on= ['ticker', 'date'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>news_category</th>\n",
       "      <th>date</th>\n",
       "      <th>stock_type</th>\n",
       "      <th>stock_date</th>\n",
       "      <th>stock_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVCY</td>\n",
       "      <td>Central Valley Community Bancorp</td>\n",
       "      <td>20170125</td>\n",
       "      <td>brief-central valley community bancorp reports...</td>\n",
       "      <td>* Reports earnings results for the year and qu...</td>\n",
       "      <td>topStory</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>short</td>\n",
       "      <td>20170126</td>\n",
       "      <td>0.0248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>20170201</td>\n",
       "      <td>brief-civeo corp announces public offering of ...</td>\n",
       "      <td>* Civeo Corporation announces public offering ...</td>\n",
       "      <td>topStory</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>short</td>\n",
       "      <td>20170202</td>\n",
       "      <td>-0.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>20170202</td>\n",
       "      <td>brief-civeo announces public offering of 20 ml...</td>\n",
       "      <td>* Civeo Corporation announces pricing of publi...</td>\n",
       "      <td>topStory</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>short</td>\n",
       "      <td>20170203</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                      company_name  publish_date  \\\n",
       "0   CVCY  Central Valley Community Bancorp      20170125   \n",
       "1   CVEO                 Civeo Corporation      20170201   \n",
       "2   CVEO                 Civeo Corporation      20170202   \n",
       "\n",
       "                                            headline  \\\n",
       "0  brief-central valley community bancorp reports...   \n",
       "1  brief-civeo corp announces public offering of ...   \n",
       "2  brief-civeo announces public offering of 20 ml...   \n",
       "\n",
       "                                      first_sentence news_category       date  \\\n",
       "0  * Reports earnings results for the year and qu...      topStory 2017-01-26   \n",
       "1  * Civeo Corporation announces public offering ...      topStory 2017-02-02   \n",
       "2  * Civeo Corporation announces pricing of publi...      topStory 2017-02-03   \n",
       "\n",
       "  stock_type  stock_date  stock_return  \n",
       "0      short    20170126        0.0248  \n",
       "1      short    20170202       -0.1028  \n",
       "2      short    20170203        0.0019  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[['ticker','company_name', 'date', 'headline', 'first_sentence', 'stock_return']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>stock_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVCY</td>\n",
       "      <td>Central Valley Community Bancorp</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>brief-central valley community bancorp reports...</td>\n",
       "      <td>* Reports earnings results for the year and qu...</td>\n",
       "      <td>0.0248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>brief-civeo corp announces public offering of ...</td>\n",
       "      <td>* Civeo Corporation announces public offering ...</td>\n",
       "      <td>-0.1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>brief-civeo announces public offering of 20 ml...</td>\n",
       "      <td>* Civeo Corporation announces pricing of publi...</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                      company_name       date  \\\n",
       "0   CVCY  Central Valley Community Bancorp 2017-01-26   \n",
       "1   CVEO                 Civeo Corporation 2017-02-02   \n",
       "2   CVEO                 Civeo Corporation 2017-02-03   \n",
       "\n",
       "                                            headline  \\\n",
       "0  brief-central valley community bancorp reports...   \n",
       "1  brief-civeo corp announces public offering of ...   \n",
       "2  brief-civeo announces public offering of 20 ml...   \n",
       "\n",
       "                                      first_sentence  stock_return  \n",
       "0  * Reports earnings results for the year and qu...        0.0248  \n",
       "1  * Civeo Corporation announces public offering ...       -0.1028  \n",
       "2  * Civeo Corporation announces pricing of publi...        0.0019  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>stock_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVCY</td>\n",
       "      <td>Central Valley Community Bancorp</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>brief-central valley community bancorp reports...</td>\n",
       "      <td>* Reports earnings results for the year and qu...</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>brief-civeo corp announces public offering of ...</td>\n",
       "      <td>* Civeo Corporation announces public offering ...</td>\n",
       "      <td>-0.1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>brief-civeo announces public offering of 20 ml...</td>\n",
       "      <td>* Civeo Corporation announces pricing of publi...</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                      company_name       date  \\\n",
       "0   CVCY  Central Valley Community Bancorp 2017-01-26   \n",
       "1   CVEO                 Civeo Corporation 2017-02-02   \n",
       "2   CVEO                 Civeo Corporation 2017-02-03   \n",
       "\n",
       "                                            headline  \\\n",
       "0  brief-central valley community bancorp reports...   \n",
       "1  brief-civeo corp announces public offering of ...   \n",
       "2  brief-civeo announces public offering of 20 ml...   \n",
       "\n",
       "                                      first_sentence  stock_return  \\\n",
       "0  * Reports earnings results for the year and qu...        0.0248   \n",
       "1  * Civeo Corporation announces public offering ...       -0.1028   \n",
       "2  * Civeo Corporation announces pricing of publi...        0.0019   \n",
       "\n",
       "   stock_label  \n",
       "0            1  \n",
       "1            0  \n",
       "2            1  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data['stock_label'] = np.where(data['stock_return'] < 0, 0, 1)\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7828, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have the dataset (with news and stock return as a binary label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>stock_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVCY</td>\n",
       "      <td>Central Valley Community Bancorp</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>brief-central valley community bancorp reports...</td>\n",
       "      <td>* Reports earnings results for the year and qu...</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2017-02-02</td>\n",
       "      <td>brief-civeo corp announces public offering of ...</td>\n",
       "      <td>* Civeo Corporation announces public offering ...</td>\n",
       "      <td>-0.1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>brief-civeo announces public offering of 20 ml...</td>\n",
       "      <td>* Civeo Corporation announces pricing of publi...</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2017-02-15</td>\n",
       "      <td>brief-renaissance technologies reports 6.2 pct...</td>\n",
       "      <td>* Renaissance Technologies LLC reports 6.20 pe...</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2017-02-22</td>\n",
       "      <td>brief-civeo corporation announces amendment to...</td>\n",
       "      <td>* Civeo Corp- Under amended credit facility  C...</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CVLY</td>\n",
       "      <td>Codorus Valley Bancorp Inc</td>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>brief-codorus valley bancorp qtrly earnings pe...</td>\n",
       "      <td>* Codorus Valley Bancorp Inc reports earnings ...</td>\n",
       "      <td>-0.0234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CWH</td>\n",
       "      <td>Camping World Holdings Inc</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>brief-camping world announces refinancing of s...</td>\n",
       "      <td>* Camping World Holdings - refinanced senior s...</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CWH</td>\n",
       "      <td>Camping World Holdings Inc</td>\n",
       "      <td>2016-11-23</td>\n",
       "      <td>brief-camping world announces acquisition of t...</td>\n",
       "      <td>* Camping World announces acquisition of Thomp...</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CZR</td>\n",
       "      <td>Caesars Entertainment Corporation</td>\n",
       "      <td>2012-08-16</td>\n",
       "      <td>text-s&amp;p revises caesars entertainment corp ra...</td>\n",
       "      <td>-- U.S. casino operator Caesars Entertainment ...</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CZR</td>\n",
       "      <td>Caesars Entertainment Corporation</td>\n",
       "      <td>2012-08-28</td>\n",
       "      <td>text-s&amp;p revises caesars linq llc and caesars ...</td>\n",
       "      <td>Overview      -- We recently revised our ratin...</td>\n",
       "      <td>-0.0627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker                       company_name       date  \\\n",
       "0   CVCY   Central Valley Community Bancorp 2017-01-26   \n",
       "1   CVEO                  Civeo Corporation 2017-02-02   \n",
       "2   CVEO                  Civeo Corporation 2017-02-03   \n",
       "3   CVEO                  Civeo Corporation 2017-02-15   \n",
       "4   CVEO                  Civeo Corporation 2017-02-22   \n",
       "5   CVLY         Codorus Valley Bancorp Inc 2017-01-20   \n",
       "6    CWH         Camping World Holdings Inc 2016-11-11   \n",
       "7    CWH         Camping World Holdings Inc 2016-11-23   \n",
       "8    CZR  Caesars Entertainment Corporation 2012-08-16   \n",
       "9    CZR  Caesars Entertainment Corporation 2012-08-28   \n",
       "\n",
       "                                            headline  \\\n",
       "0  brief-central valley community bancorp reports...   \n",
       "1  brief-civeo corp announces public offering of ...   \n",
       "2  brief-civeo announces public offering of 20 ml...   \n",
       "3  brief-renaissance technologies reports 6.2 pct...   \n",
       "4  brief-civeo corporation announces amendment to...   \n",
       "5  brief-codorus valley bancorp qtrly earnings pe...   \n",
       "6  brief-camping world announces refinancing of s...   \n",
       "7  brief-camping world announces acquisition of t...   \n",
       "8  text-s&p revises caesars entertainment corp ra...   \n",
       "9  text-s&p revises caesars linq llc and caesars ...   \n",
       "\n",
       "                                      first_sentence  stock_return  \\\n",
       "0  * Reports earnings results for the year and qu...        0.0248   \n",
       "1  * Civeo Corporation announces public offering ...       -0.1028   \n",
       "2  * Civeo Corporation announces pricing of publi...        0.0019   \n",
       "3  * Renaissance Technologies LLC reports 6.20 pe...        0.0136   \n",
       "4  * Civeo Corp- Under amended credit facility  C...       -0.0020   \n",
       "5  * Codorus Valley Bancorp Inc reports earnings ...       -0.0234   \n",
       "6  * Camping World Holdings - refinanced senior s...        0.0793   \n",
       "7  * Camping World announces acquisition of Thomp...        0.0336   \n",
       "8  -- U.S. casino operator Caesars Entertainment ...       -0.0095   \n",
       "9  Overview      -- We recently revised our ratin...       -0.0627   \n",
       "\n",
       "   stock_label  \n",
       "0            1  \n",
       "1            0  \n",
       "2            1  \n",
       "3            1  \n",
       "4            0  \n",
       "5            0  \n",
       "6            1  \n",
       "7            1  \n",
       "8            0  \n",
       "9            0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 6738\n"
     ]
    }
   ],
   "source": [
    "# Find the number of times each word was used and the size of the vocabulary\n",
    "word_counts = {}\n",
    "\n",
    "for news in data['headline']:\n",
    "    for word in data['headline']:\n",
    "        if word not in word_counts:\n",
    "            word_counts[word] = 1\n",
    "        else:\n",
    "            word_counts[word] += 1\n",
    "            \n",
    "print(\"Size of Vocabulary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"SJ_HW4_formatted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('SJ_HW4_formatted.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>stock_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CVCY</td>\n",
       "      <td>Central Valley Community Bancorp</td>\n",
       "      <td>1/26/17</td>\n",
       "      <td>brief-central valley community bancorp reports...</td>\n",
       "      <td>* Reports earnings results for the year and qu...</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2/2/17</td>\n",
       "      <td>brief-civeo corp announces public offering of ...</td>\n",
       "      <td>* Civeo Corporation announces public offering ...</td>\n",
       "      <td>-0.1028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CVEO</td>\n",
       "      <td>Civeo Corporation</td>\n",
       "      <td>2/3/17</td>\n",
       "      <td>brief-civeo announces public offering of 20 ml...</td>\n",
       "      <td>* Civeo Corporation announces pricing of publi...</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 ticker                      company_name     date  \\\n",
       "0           0   CVCY  Central Valley Community Bancorp  1/26/17   \n",
       "1           1   CVEO                 Civeo Corporation   2/2/17   \n",
       "2           2   CVEO                 Civeo Corporation   2/3/17   \n",
       "\n",
       "                                            headline  \\\n",
       "0  brief-central valley community bancorp reports...   \n",
       "1  brief-civeo corp announces public offering of ...   \n",
       "2  brief-civeo announces public offering of 20 ml...   \n",
       "\n",
       "                                      first_sentence  stock_return  \\\n",
       "0  * Reports earnings results for the year and qu...        0.0248   \n",
       "1  * Civeo Corporation announces public offering ...       -0.1028   \n",
       "2  * Civeo Corporation announces pricing of publi...        0.0019   \n",
       "\n",
       "   stock_label  \n",
       "0            1  \n",
       "1            0  \n",
       "2            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6810, 8) (1018, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, \n",
    "                               test_size = .13, \n",
    "                               random_state=25)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set and Test set are ready!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6810,) (1018,) (6810,) (1018,)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset into train (85%) and test (15%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['headline'], \n",
    "                                                    data['stock_label'], \n",
    "                                                    test_size = .13, \n",
    "                                                    random_state=25)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building word2vec model\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import string\n",
    "\n",
    "sentences = []\n",
    "for item in data['headline']:\n",
    "    sentences.extend([[w.translate(str.maketrans('','',string.punctuation)).strip().lower() for w in sent.split()]\\\n",
    "                      for sent in PunktSentenceTokenizer().tokenize(item)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "w2v_model = gensim.models.Word2Vec (sentences, size=150, window=10, min_count=2, workers=10)\n",
    "w2v_model.train(sentences,total_examples=len(sentences),epochs=10)\n",
    "w2v = dict(zip(w2v_model.wv.index2word, w2v_model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('direct', 0.995242714881897),\n",
       " ('charter', 0.9940692186355591),\n",
       " ('updates', 0.9937134385108948),\n",
       " ('briefdiana', 0.9928981065750122),\n",
       " ('puerto', 0.9928292632102966),\n",
       " ('disposal', 0.9926966428756714),\n",
       " ('approved', 0.9925059080123901),\n",
       " ('rico', 0.992316722869873),\n",
       " ('continuation', 0.9921209216117859),\n",
       " ('support', 0.9917473196983337)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking word2vec model\n",
    "w2v_model.similar_by_word('public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6810,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 classes\n",
      "Vectorizing sequence data...\n",
      "x_train shape: (6810,)\n",
      "x_test shape: (1018,)\n",
      "y_train shape: (6810,)\n",
      "y_test shape: (1018,)\n"
     ]
    }
   ],
   "source": [
    "#Build a neural net model using word2vec embeddings (both pretrained and within an Embedding layer from Keras\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, Flatten\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 250\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "num_classes = 2\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "x_train = tokenizer.texts_to_matrix(X_train)\n",
    "x_test = tokenizer.texts_to_matrix(X_test)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)\n",
    "\n",
    "# Borrow our binarized labels from the previous model\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = train['stock_label']\n",
    "train_label = train_label.reshape((6810, 1))\n",
    "type(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we have the train set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import string\n",
    "\n",
    "sentences = []\n",
    "for item in data['headline']:\n",
    "    sentences.extend([[w.translate(str.maketrans('','',string.punctuation)).strip().lower() for w in sent.split()]\\\n",
    "                      for sent in PunktSentenceTokenizer().tokenize(item)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['textsp', 'rates', 'caesars', 'entertainments', 'proposed', 'notes', 'b'],\n",
       " ['briefboyd', 'and', 'caesars', 'jump', 'in', 'afternoon', 'trading'],\n",
       " ['textfitch', 'imminent', 'online', 'gaming', 'in', 'nj']]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[15:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec (sentences, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(sentences,total_examples=len(sentences),epochs=10)\n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('briefdiana', 0.9951826930046082),\n",
       " ('notes', 0.9946377277374268),\n",
       " ('fund', 0.9930644035339355),\n",
       " ('offering', 0.9923483729362488),\n",
       " ('growing', 0.9918162226676941),\n",
       " ('support', 0.9897124171257019),\n",
       " ('direct', 0.9886226058006287),\n",
       " ('holdings', 0.9884518384933472),\n",
       " ('advisers', 0.9878647327423096),\n",
       " ('completes', 0.987798810005188)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking word2vec model\n",
    "model.similar_by_word('public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 classes\n",
      "Vectorizing sequence data...\n",
      "x_train shape: (6810,)\n",
      "x_test shape: (1018,)\n",
      "y_train shape: (6810,)\n",
      "y_test shape: (1018,)\n"
     ]
    }
   ],
   "source": [
    "#Build a neural net model using word2vec embeddings (both pretrained and within an Embedding layer from Keras\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, Flatten\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 214\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "num_classes = 2\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "x_train = tokenizer.texts_to_matrix(X_train)\n",
    "x_test = tokenizer.texts_to_matrix(X_test)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)\n",
    "\n",
    "# Borrow our binarized labels from the previous model\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6810, 400)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length in headline is:  214\n"
     ]
    }
   ],
   "source": [
    "## Get length of longest sequence\n",
    "max_seq_len = max([len(idx_seq) for idx_seq in data['headline']])\n",
    "print(\"Max length in headline is: \", max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[13:14, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6361    1\n",
       "Name: stock_label, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[13:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "X_train_tokenized = [word_tokenize(x) for x in X_train]\n",
    "X_test_tokenized = [word_tokenize(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "def isSymbol(inputString):\n",
    "    return bool(re.match(r'[^\\w]', inputString))\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def check(word):\n",
    "    if word in stop:\n",
    "        return False\n",
    "    elif hasNumbers(word) or isSymbol(word):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def preprocessing(sen):\n",
    "    res = []\n",
    "    for word in sen:  \n",
    "        if check(word): \n",
    "            word = word.lower().replace(\".\", '').replace('\"', '').replace(\"'\", '')\n",
    "            res.append(wordnet_lemmatizer.lemmatize(word))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_processed = [preprocessing(x) for x in X_train_tokenized]\n",
    "X_test_processed = [preprocessing(x) for x in X_test_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ge', 'mammography', 'device', 'get', 'u', 'fda', 'approval']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed[0]\n",
    "X_test_processed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "model_w2v = Word2Vec(X_train_processed, size=400, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03800208, -0.13542098, -0.05232017,  0.05867366,  0.03618153,\n",
       "        0.05351061, -0.01684152, -0.04570716,  0.06966811,  0.03118808,\n",
       "        0.01305857, -0.04003138,  0.01996516,  0.00277247,  0.01923244,\n",
       "        0.1010325 , -0.00668759,  0.05723053,  0.05684376,  0.07368633,\n",
       "       -0.00032078, -0.00496446, -0.05285033, -0.0207696 , -0.06006723,\n",
       "        0.02183884,  0.06949441, -0.04099743,  0.03313633, -0.04996708,\n",
       "        0.017782  ,  0.08012734, -0.02781224, -0.10544675,  0.00986416,\n",
       "       -0.01352925,  0.1012539 ,  0.0549473 , -0.06386796,  0.00466527,\n",
       "       -0.11189996,  0.01975877,  0.05812088,  0.11149258, -0.01931848,\n",
       "       -0.04613898, -0.02669925, -0.0267346 , -0.0046218 , -0.01631208,\n",
       "        0.03660669,  0.12000056, -0.03243194,  0.04035706, -0.05602781,\n",
       "        0.00073939,  0.00186324,  0.03259039,  0.03362983,  0.07117146,\n",
       "       -0.12409593, -0.05546589, -0.02826298, -0.02625254,  0.00727845,\n",
       "       -0.01028248,  0.05686618, -0.08262352,  0.02459825,  0.08491518,\n",
       "       -0.02624177, -0.04665577,  0.0146081 , -0.04933835, -0.0141057 ,\n",
       "        0.06600346,  0.04036926,  0.02649754,  0.05186013,  0.0511397 ,\n",
       "        0.0595527 ,  0.06204426, -0.02045428,  0.00864807,  0.01518632,\n",
       "        0.04744283, -0.02464596, -0.07154908, -0.006587  ,  0.01572485,\n",
       "       -0.0095083 ,  0.02275896, -0.01911968,  0.06922285, -0.04951476,\n",
       "        0.03590179,  0.05130014, -0.06261617, -0.05340537,  0.12275127,\n",
       "       -0.10587504, -0.10237098,  0.05628616,  0.02314524,  0.00743609,\n",
       "        0.01520294,  0.03928356, -0.02936006,  0.02013014, -0.02573694,\n",
       "        0.02695272, -0.00130563, -0.04937962,  0.0140403 , -0.00675956,\n",
       "       -0.00471246, -0.00243943,  0.00036694, -0.00395204,  0.01454541,\n",
       "       -0.01139016,  0.03207035, -0.03017269, -0.06128483,  0.08816851,\n",
       "        0.01354258,  0.09767869,  0.01416717,  0.05380177,  0.00826026,\n",
       "       -0.06651133,  0.02608266, -0.01161149,  0.0262956 , -0.0025405 ,\n",
       "       -0.01074231,  0.00462328, -0.07854909, -0.02740479, -0.04720065,\n",
       "        0.05463079,  0.01797184, -0.03815231,  0.02558693, -0.03337483,\n",
       "        0.03094272, -0.01068872,  0.02703696, -0.07779941,  0.04612764,\n",
       "        0.03512321,  0.02585754,  0.05798225, -0.00699577,  0.01992356,\n",
       "        0.0228627 , -0.01458923, -0.07853844, -0.01502253, -0.05695399,\n",
       "       -0.02854374,  0.03216113,  0.01907977,  0.08506577, -0.00353707,\n",
       "       -0.05037219,  0.03012023, -0.05522869,  0.00324697, -0.02575281,\n",
       "        0.065554  ,  0.04701113, -0.05078837, -0.09957538, -0.05774829,\n",
       "       -0.00888224, -0.03159033, -0.0056098 ,  0.05143247,  0.11884539,\n",
       "       -0.03233968, -0.00814383, -0.07341807, -0.06233019, -0.08432202,\n",
       "       -0.03285807, -0.00523307,  0.01762331, -0.10901666, -0.00221412,\n",
       "       -0.09161195, -0.04477794,  0.01925708,  0.0587404 , -0.00834537,\n",
       "        0.01063179, -0.03490583, -0.00679852,  0.02306188, -0.00961147,\n",
       "        0.02772181, -0.01014812, -0.0302226 , -0.00208416, -0.01690634,\n",
       "       -0.02695331,  0.02159789, -0.05603003, -0.10819953,  0.10107198,\n",
       "       -0.02412626, -0.03284269,  0.04255325, -0.06933438, -0.00986839,\n",
       "       -0.07585483,  0.02298228, -0.00816192, -0.07545879,  0.01094922,\n",
       "        0.00909714, -0.00803624, -0.01712113,  0.00898651, -0.04366146,\n",
       "        0.01023435,  0.01281345, -0.03766783,  0.05926307,  0.0239199 ,\n",
       "       -0.05128468,  0.00652546,  0.05358493,  0.00232367,  0.04377375,\n",
       "       -0.0529932 , -0.02372804,  0.03310307,  0.01821122, -0.03397748,\n",
       "       -0.03519727, -0.0796084 , -0.06215208, -0.02996464, -0.00462206,\n",
       "        0.01636997,  0.03139777,  0.0625023 ,  0.07197417, -0.09100506,\n",
       "        0.01762766,  0.02910039,  0.00638402, -0.04871477,  0.0197072 ,\n",
       "       -0.01663247, -0.03783277,  0.02165159, -0.01199245,  0.00564545,\n",
       "        0.00754222, -0.02486967, -0.09124916,  0.04713846,  0.04224813,\n",
       "       -0.04122335,  0.03576927,  0.00643974, -0.02081247,  0.03701487,\n",
       "        0.03473312,  0.05170153, -0.02112889,  0.05057409, -0.00072823,\n",
       "        0.07988833,  0.00265391, -0.00930834, -0.01707021, -0.03427432,\n",
       "       -0.04348284, -0.04793149,  0.05549089, -0.01634136,  0.01805277,\n",
       "        0.01898401,  0.04006235,  0.06223018,  0.01506761, -0.02444927,\n",
       "        0.06479417, -0.0236515 ,  0.05634995,  0.07328845, -0.03484724,\n",
       "       -0.02608824, -0.00904821,  0.00627161, -0.02040409, -0.05513669,\n",
       "        0.05178715, -0.0694575 , -0.03794528,  0.02336728,  0.01774842,\n",
       "       -0.08413225, -0.0695956 , -0.01895569,  0.04175257, -0.0051331 ,\n",
       "       -0.08731919, -0.01504659, -0.03610989,  0.01422973, -0.03862698,\n",
       "        0.00033375, -0.03052922, -0.03044149, -0.00932856,  0.04841444,\n",
       "        0.02660824,  0.00530028,  0.01159515,  0.04525589,  0.0351558 ,\n",
       "        0.08000767, -0.02564427, -0.0569551 , -0.01653861, -0.0323041 ,\n",
       "        0.0599145 , -0.02671386,  0.01114689, -0.00802812, -0.08514372,\n",
       "        0.03598443, -0.03428465, -0.03655777,  0.07024749,  0.02048613,\n",
       "       -0.01306919,  0.00368504,  0.03049597,  0.00170429,  0.00858603,\n",
       "       -0.0391899 ,  0.00025661, -0.00799759, -0.09615522,  0.00819494,\n",
       "        0.01488536,  0.02436113,  0.05079896, -0.05573229, -0.05417057,\n",
       "        0.04502463, -0.0731867 ,  0.04860697, -0.06039755,  0.0138504 ,\n",
       "       -0.13695197, -0.07078106,  0.09724417,  0.0796793 ,  0.00074258,\n",
       "        0.02632277,  0.00389632, -0.0660696 , -0.09838301,  0.02504016,\n",
       "        0.06360654,  0.13148616, -0.00026713,  0.05534134, -0.00356829,\n",
       "       -0.02259715, -0.03438644,  0.04226161,  0.04221183, -0.00914376,\n",
       "       -0.01665655, -0.00629031,  0.03960429,  0.04761398,  0.05698882,\n",
       "        0.00014723, -0.01087861, -0.02374027, -0.0331261 , -0.02586585,\n",
       "       -0.04367534,  0.03901804, -0.00554643,  0.02976206,  0.06809605,\n",
       "        0.03809656, -0.00497388,  0.01279825, -0.07815363,  0.00735777],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv['public']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = model_w2v.wv.vocab\n",
    "\n",
    "def get_vector(word_list):\n",
    "    res = np.zeros([400])\n",
    "    count=0\n",
    "    for word in word_list:\n",
    "        res += model[word]\n",
    "        count += 1\n",
    "    return res/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'aisle' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-163-c306e7c3850b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train_processed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test_processed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-163-c306e7c3850b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train_processed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test_processed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-162-45144f50b67e>\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(word_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m                 )\n\u001b[0;32m-> 1368\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \"\"\"\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.__contains__() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'aisle' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "X_train_w2v = [get_vector(x) for x in X_train_processed]\n",
    "X_test_w2v = [get_vector(x) for x in X_test_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def build_vocab(filename):\n",
    "    data = X_train\n",
    "\n",
    "    counter = collections.Counter(data)\n",
    "    count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "\n",
    "    words, _ = list(zip(*count_pairs))\n",
    "    word_to_id = dict(zip(words, range(len(words))))\n",
    "\n",
    "    return word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = build_vocab(x_train)\n",
    "vocabulary = len(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5974"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_to_word_ids(filename, word_to_id):\n",
    "    data = X_train\n",
    "    return [word_to_id[word] for word in data if word in word_to_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = file_to_word_ids(X_train, word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6810"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create lexicons + index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6810, 8) (1018, 8)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "train['text_tokenized'] = [word_tokenize(x) for x in train['headline']]\n",
    "test['text_tokenized'] = [word_tokenize(x) for x in test['headline']]\n",
    "\n",
    "data['headline_tokenized'] = [word_tokenize(x) for x in data['headline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>stock_label</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>518</td>\n",
       "      <td>DIS</td>\n",
       "      <td>Walt Disney Company (The)</td>\n",
       "      <td>10/6/11</td>\n",
       "      <td>wal-mart goes back to basics in holiday toy ai...</td>\n",
       "      <td>NORTH BERGEN  New Jersey Wal-Mart is taking cu...</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0</td>\n",
       "      <td>[wal-mart, goes, back, to, basics, in, holiday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>5204</td>\n",
       "      <td>JD</td>\n",
       "      <td>JDcom Inc</td>\n",
       "      <td>5/13/15</td>\n",
       "      <td>alibaba rolls out 3-hour delivery service for ...</td>\n",
       "      <td>BEIJING  May 12 Chinese online shopping giant ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>[alibaba, rolls, out, 3-hour, delivery, servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>6516</td>\n",
       "      <td>MAR</td>\n",
       "      <td>Marriott International</td>\n",
       "      <td>10/7/16</td>\n",
       "      <td>corrected-update 1-marriott expands in south a...</td>\n",
       "      <td>JOHANNESBURG  Oct 6 Marriott International  sa...</td>\n",
       "      <td>-0.0022</td>\n",
       "      <td>0</td>\n",
       "      <td>[corrected-update, 1-marriott, expands, in, so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 ticker               company_name     date  \\\n",
       "518          518    DIS  Walt Disney Company (The)  10/6/11   \n",
       "5204        5204     JD                  JDcom Inc  5/13/15   \n",
       "6516        6516    MAR     Marriott International  10/7/16   \n",
       "\n",
       "                                               headline  \\\n",
       "518   wal-mart goes back to basics in holiday toy ai...   \n",
       "5204  alibaba rolls out 3-hour delivery service for ...   \n",
       "6516  corrected-update 1-marriott expands in south a...   \n",
       "\n",
       "                                         first_sentence  stock_return  \\\n",
       "518   NORTH BERGEN  New Jersey Wal-Mart is taking cu...       -0.0018   \n",
       "5204  BEIJING  May 12 Chinese online shopping giant ...        0.0000   \n",
       "6516  JOHANNESBURG  Oct 6 Marriott International  sa...       -0.0022   \n",
       "\n",
       "      stock_label                                     text_tokenized  \n",
       "518             0  [wal-mart, goes, back, to, basics, in, holiday...  \n",
       "5204            1  [alibaba, rolls, out, 3-hour, delivery, servic...  \n",
       "6516            0  [corrected-update, 1-marriott, expands, in, so...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create lexicon\n",
    "\n",
    "import pickle\n",
    "\n",
    "def make_lexicon(token_seqs, min_freq=1):\n",
    "    # First, count how often each word appears in the text.\n",
    "    token_counts = {}\n",
    "    for news in token_seqs:\n",
    "        for word in news:\n",
    "            if word in token_counts:\n",
    "                token_counts[word] += 1\n",
    "            else:\n",
    "                token_counts[word] = 1\n",
    "\n",
    "    # Then, assign each word to a numerical index. Filter words that occur less than min_freq times.\n",
    "    lexicon = [token for token, count in token_counts.items() if count >= min_freq]\n",
    "    # Indices start at 1. 0 is reserved for padding, and 1 is reserved for unknown words.\n",
    "    lexicon = {token:idx + 2 for idx,token in enumerate(lexicon)}\n",
    "    lexicon[u'<UNK>'] = 1 # Unknown words are those that occur fewer than min_freq times\n",
    "    lexicon_size = len(lexicon)\n",
    "\n",
    "    print(\"LEXICON SAMPLE ({} total items):\".format(len(lexicon)))\n",
    "    print(dict(list(lexicon.items())[:20]))\n",
    "    \n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS:\n",
      "LEXICON SAMPLE (8912 total items):\n",
      "{'brief-central': 2, 'valley': 3, 'community': 4, 'bancorp': 5, 'reports': 6, 'q4': 7, 'eps': 8, '$': 9, '0.21': 10, 'brief-civeo': 11, 'corp': 12, 'announces': 13, 'public': 14, 'offering': 15, 'of': 16, 'common': 17, 'shares': 18, '20': 19, 'mln': 20, 'brief-renaissance': 21}\n"
     ]
    }
   ],
   "source": [
    "print(\"WORDS:\")\n",
    "words_lexicon = make_lexicon(data['headline_tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens_to_idxs(token_seqs, lexicon):\n",
    "    #idx_seqs = [[lexicon[token] if token in lexicon else lexicon['<UNK>'] for token in token_seq]  \n",
    "    #                                                                 for token_seq in token_seqs]\n",
    "    #idx_seqs = [[lexicon[token] if token in lexicon else lexicon['<UNK>'] ] for token in token_seqs]  \n",
    "    idx_seqs = [[lexicon[token] if token in lexicon else lexicon['<UNK>'] for token in token_seq]  \n",
    "                                                                     for token_seq in token_seqs]                                                                 \n",
    "    return idx_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tokenized_idx</th>\n",
       "      <th>stock_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[wal-mart, goes, back, to, basics, in, holiday...</td>\n",
       "      <td>[1154, 1155, 1129, 31, 1156, 27, 1015, 1157, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>[alibaba, rolls, out, 3-hour, delivery, servic...</td>\n",
       "      <td>[4637, 1026, 126, 6810, 4573, 1427, 92, 1021, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>[corrected-update, 1-marriott, expands, in, so...</td>\n",
       "      <td>[530, 7862, 1001, 27, 197, 3156, 448, 1426, 11...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6581</th>\n",
       "      <td>[two, mediobanca, board, members, quit, in, li...</td>\n",
       "      <td>[1519, 7898, 162, 586, 3617, 27, 2092, 448, 11...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>[update, 1-big, hedge, funds, shopped, at, j.c...</td>\n",
       "      <td>[110, 4330, 327, 328, 6693, 145, 3024, 3025, 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>[update, 2-apple, plans, fix, next, week, for,...</td>\n",
       "      <td>[110, 4338, 130, 4935, 2145, 540, 92, 2665, 49...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>[ge, points, way, for, 'too, big, to, fail, ',...</td>\n",
       "      <td>[2959, 3548, 3363, 92, 3549, 836, 31, 983, 81,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>[refile-update, 2-gamestop, 's, forecast, miss...</td>\n",
       "      <td>[1549, 4258, 72, 2818, 2682, 68, 1184, 4257, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5656</th>\n",
       "      <td>[update, 1-banking, venture, nbnk, in, talks, ...</td>\n",
       "      <td>[110, 7205, 263, 7188, 27, 218, 244, 45]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>[fitch, downgrades, j.c., penney, on, strategy...</td>\n",
       "      <td>[185, 208, 3024, 3025, 68, 3200, 905]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_tokenized  \\\n",
       "518   [wal-mart, goes, back, to, basics, in, holiday...   \n",
       "5204  [alibaba, rolls, out, 3-hour, delivery, servic...   \n",
       "6516  [corrected-update, 1-marriott, expands, in, so...   \n",
       "6581  [two, mediobanca, board, members, quit, in, li...   \n",
       "5080  [update, 1-big, hedge, funds, shopped, at, j.c...   \n",
       "3168  [update, 2-apple, plans, fix, next, week, for,...   \n",
       "1928  [ge, points, way, for, 'too, big, to, fail, ',...   \n",
       "2596  [refile-update, 2-gamestop, 's, forecast, miss...   \n",
       "5656  [update, 1-banking, venture, nbnk, in, talks, ...   \n",
       "4747  [fitch, downgrades, j.c., penney, on, strategy...   \n",
       "\n",
       "                                     text_tokenized_idx  stock_label  \n",
       "518   [1154, 1155, 1129, 31, 1156, 27, 1015, 1157, 1...            0  \n",
       "5204  [4637, 1026, 126, 6810, 4573, 1427, 92, 1021, ...            1  \n",
       "6516  [530, 7862, 1001, 27, 197, 3156, 448, 1426, 11...            0  \n",
       "6581  [1519, 7898, 162, 586, 3617, 27, 2092, 448, 11...            1  \n",
       "5080  [110, 4330, 327, 328, 6693, 145, 3024, 3025, 2...            1  \n",
       "3168  [110, 4338, 130, 4935, 2145, 540, 92, 2665, 49...            1  \n",
       "1928  [2959, 3548, 3363, 92, 3549, 836, 31, 983, 81,...            0  \n",
       "2596  [1549, 4258, 72, 2818, 2682, 68, 1184, 4257, 1...            0  \n",
       "5656           [110, 7205, 263, 7188, 27, 218, 244, 45]            1  \n",
       "4747              [185, 208, 3024, 3025, 68, 3200, 905]            1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train['Word_Idxs'] = tokens_to_idxs(train['Tokenized_Words'], words_lexicon)\n",
    "train['text_tokenized_idx'] = tokens_to_idxs(train['text_tokenized'], words_lexicon)\n",
    "train[['text_tokenized', 'text_tokenized_idx', 'stock_label']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/shuixin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "### then padding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def pad_idx_seqs(idx_seqs, max_seq_len):\n",
    "    # Keras provides a convenient padding function; \n",
    "    padded_idxs = pad_sequences(sequences=idx_seqs, maxlen=max_seq_len)\n",
    "    return padded_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORDS:\n",
      " [[   0    0    0 ... 1015 1157 1158]\n",
      " [   0    0    0 ...   92 1021 2155]\n",
      " [   0    0    0 ... 1426  113 6995]\n",
      " ...\n",
      " [   0    0    0 ...  264  162  703]\n",
      " [   0    0    0 ...   16  446   76]\n",
      " [   0    0    0 ... 1241   31 1532]]\n",
      "SHAPE: (6810, 33) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = max([len(idx_seq) for idx_seq in train['text_tokenized_idx']]) # Get length of longest sequence\n",
    "train_padded_words = pad_idx_seqs(train['text_tokenized_idx'], \n",
    "                                  max_seq_len + 1) #Add one to max length for offsetting sequence by 1\n",
    "\n",
    "print(\"WORDS:\\n\", train_padded_words)\n",
    "print(\"SHAPE:\", train_padded_words.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_43 (Embedding)     (None, 33, 20)            178260    \n",
      "_________________________________________________________________\n",
      "simple_rnn_11 (SimpleRNN)    (None, 100)               12100     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 190,461\n",
      "Trainable params: 190,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.layers import Input, Concatenate, TimeDistributed, Dense\n",
    "from keras.layers import Activation,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,MaxPooling1D,Flatten\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import RandomUniform\n",
    "\n",
    "hidden_size = 500\n",
    "max_length = 33\n",
    "num_steps = 30\n",
    "vocabulary = 5974\n",
    "n_class = 1\n",
    "n_word_input_nodes=len(words_lexicon) + 1, #Add one for 0 padding\n",
    "\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(input_dim=n_word_input_nodes[0],\n",
    "                     input_length=max_length,\n",
    "                     output_dim=20, \n",
    "                     mask_zero=True))\n",
    "#model_rnn.add(Flatten())\n",
    "model_rnn.add(SimpleRNN(100, return_sequences=False))\n",
    "model_rnn.add(Dropout(0.25))\n",
    "model_rnn.add(Dense(n_class, activation=\"sigmoid\"))\n",
    "\n",
    "#model_rnn.add(Embedding(max_words, 100, input_length= x_train.shape[1]))\n",
    "#model_rnn.add(Flatten())\n",
    "#model_rnn.add(LSTM(hidden_size, return_sequences=True))\n",
    "#model_rnn.add(Dense(256, input_shape=(max_words,)))\n",
    "#model_rnn.add(Activation('relu'))\n",
    "#model_rnn.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "#model_rnn.add(TimeDistributed(Dense(n_class, activation = 'softmax')))\n",
    "\n",
    "#model_rnn.add(LSTM(hidden_size, return_sequences=True))\n",
    "#model_rnn.add(LSTM(hidden_size, return_sequences=True))\n",
    "#if use_dropout:\n",
    "#    model_rnn.add(Dropout(0.5))\n",
    "#model_rnn.add(TimeDistributed(Dense(vocabulary)))\n",
    "#model_rnn.add(Flatten())\n",
    "#model_rnn.add(Activation('softmax'))\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0, 1154, 1155, 1129,   31, 1156,   27, 1015, 1157, 1158],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6810"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['stock_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = train['stock_label']\n",
    "train_label = train_label.reshape((6810, 1))\n",
    "type(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6129 samples, validate on 681 samples\n",
      "Epoch 1/5\n",
      "6129/6129 [==============================] - 6s 1ms/step - loss: 0.6804 - acc: 0.5590 - val_loss: 0.6537 - val_acc: 0.6197\n",
      "Epoch 2/5\n",
      "6129/6129 [==============================] - 4s 597us/step - loss: 0.4321 - acc: 0.8086 - val_loss: 0.6287 - val_acc: 0.6960\n",
      "Epoch 3/5\n",
      "6129/6129 [==============================] - 4s 588us/step - loss: 0.1752 - acc: 0.9336 - val_loss: 0.7163 - val_acc: 0.6916\n",
      "Epoch 4/5\n",
      "6129/6129 [==============================] - 4s 587us/step - loss: 0.0992 - acc: 0.9662 - val_loss: 0.8344 - val_acc: 0.7063\n",
      "Epoch 5/5\n",
      "6129/6129 [==============================] - 4s 596us/step - loss: 0.0780 - acc: 0.9732 - val_loss: 0.9361 - val_acc: 0.6916\n"
     ]
    }
   ],
   "source": [
    "rnn_fit = model_rnn.fit(x = train_padded_words, #y = train['stock_label'],\n",
    "                        y = train_label,\n",
    "                        batch_size=32,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "##process the test set\n",
    "test['text_tokenized_idx'] = tokens_to_idxs(test['text_tokenized'], words_lexicon)\n",
    "\n",
    "#max_seq_len = max([len(idx_seq) for idx_seq in train['text_tokenized_idx']]) # Get length of longest sequence\n",
    "test_padded_words = pad_idx_seqs(test['text_tokenized_idx'], \n",
    "                                  max_seq_len + 1) #Add one to max length for offsetting sequence by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_len = max([len(idx_seq) for idx_seq in train['text_tokenized_idx']])\n",
    "max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_padded_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label = test['stock_label']\n",
    "test_label = test_label.reshape((1018, 1))\n",
    "type(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 0s 148us/step\n",
      "Test score: 0.8676007067993254\n",
      "Test accuracy: 0.6905697442459451\n"
     ]
    }
   ],
   "source": [
    "score = model_rnn.evaluate(test_padded_words, test_label,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_pred = model_rnn.predict(test_padded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['rnn_pred'] = rnn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "def label_recode(series):\n",
    "    if series < 0.5 :\n",
    "        return 0\n",
    "    elif series >= 0.5 :\n",
    "        return 1\n",
    "    \n",
    "test['rnn_pred'] = test['rnn_pred'].apply(label_recode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.61\n",
      "Recall Score: 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, recall_score\n",
    "\n",
    "rnn_precision = average_precision_score(test['stock_label'], test['rnn_pred'])\n",
    "rnn_recall = recall_score(test['stock_label'], test['rnn_pred'], average=\"macro\")\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      rnn_precision))\n",
    "print('Recall Score: {0:0.2f}'.format(\n",
    "      rnn_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>stock_label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tokenized_idx</th>\n",
       "      <th>rnn_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>1790</td>\n",
       "      <td>GEK</td>\n",
       "      <td>General Electric Capital Corporation</td>\n",
       "      <td>9/4/14</td>\n",
       "      <td>ge's 3d mammography device gets u.s. fda appro...</td>\n",
       "      <td>Sept 2 General Electric Co's healthcare unit l...</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0</td>\n",
       "      <td>[ge, 's, 3d, mammography, device, gets, u.s., ...</td>\n",
       "      <td>[2959, 72, 1087, 3408, 3409, 382, 219, 1927, 203]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>5550</td>\n",
       "      <td>LW</td>\n",
       "      <td>Lamb Weston Holdings Inc</td>\n",
       "      <td>1/11/17</td>\n",
       "      <td>brief-lamb weston reports fiscal q2 2017 eps $...</td>\n",
       "      <td>* Q2 earnings per share view $0.55 -- Thomson ...</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0</td>\n",
       "      <td>[brief-lamb, weston, reports, fiscal, q2, 2017...</td>\n",
       "      <td>[7077, 7078, 6, 1524, 1805, 1871, 8, 9, 7079]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>4639</td>\n",
       "      <td>IRMD</td>\n",
       "      <td>iRadimed Corporation</td>\n",
       "      <td>2/7/17</td>\n",
       "      <td>brief-iradimed corp q4 non-gaap eps $0.11</td>\n",
       "      <td>* Iradimed Corporation announces fourth quarte...</td>\n",
       "      <td>-0.0292</td>\n",
       "      <td>0</td>\n",
       "      <td>[brief-iradimed, corp, q4, non-gaap, eps, $, 0...</td>\n",
       "      <td>[6305, 12, 7, 4265, 8, 9, 6306]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1094</td>\n",
       "      <td>EQT</td>\n",
       "      <td>EQT Corporation</td>\n",
       "      <td>5/3/16</td>\n",
       "      <td>brief-eqt intends to commence public offering ...</td>\n",
       "      <td>* Intends to commence a registered public offe...</td>\n",
       "      <td>-0.0084</td>\n",
       "      <td>0</td>\n",
       "      <td>[brief-eqt, intends, to, commence, public, off...</td>\n",
       "      <td>[2053, 2286, 31, 2287, 14, 15, 16, 472, 20, 18]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>4084</td>\n",
       "      <td>IBM</td>\n",
       "      <td>International Business Machines Corporation</td>\n",
       "      <td>12/4/13</td>\n",
       "      <td>google takes on amazon by cutting cloud servic...</td>\n",
       "      <td>SAN FRANCISCO  Dec 3 Google Inc will lower pri...</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0</td>\n",
       "      <td>[google, takes, on, amazon, by, cutting, cloud...</td>\n",
       "      <td>[2756, 959, 68, 2975, 360, 3660, 1626, 1427, 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1318</td>\n",
       "      <td>FOX</td>\n",
       "      <td>Twenty-First Century Fox Inc</td>\n",
       "      <td>10/22/15</td>\n",
       "      <td>australia waves through news corp buy-in to st...</td>\n",
       "      <td>SYDNEY  Oct 22 Australia's antitrust regulator...</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1</td>\n",
       "      <td>[australia, waves, through, news, corp, buy-in...</td>\n",
       "      <td>[2122, 2707, 2275, 882, 12, 2708, 31, 2709, 27...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>3922</td>\n",
       "      <td>IBM</td>\n",
       "      <td>International Business Machines Corporation</td>\n",
       "      <td>5/31/12</td>\n",
       "      <td>text-s&amp;p raises ibm ratings</td>\n",
       "      <td>Overview\\t      -- U.S. technology and solutio...</td>\n",
       "      <td>-0.0062</td>\n",
       "      <td>0</td>\n",
       "      <td>[text-s, &amp;, p, raises, ibm, ratings]</td>\n",
       "      <td>[49, 50, 51, 693, 5288, 213]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 ticker                                 company_name  \\\n",
       "1790        1790    GEK         General Electric Capital Corporation   \n",
       "5550        5550     LW                     Lamb Weston Holdings Inc   \n",
       "4639        4639   IRMD                         iRadimed Corporation   \n",
       "1094        1094    EQT                              EQT Corporation   \n",
       "4084        4084    IBM  International Business Machines Corporation   \n",
       "1318        1318    FOX                 Twenty-First Century Fox Inc   \n",
       "3922        3922    IBM  International Business Machines Corporation   \n",
       "\n",
       "          date                                           headline  \\\n",
       "1790    9/4/14  ge's 3d mammography device gets u.s. fda appro...   \n",
       "5550   1/11/17  brief-lamb weston reports fiscal q2 2017 eps $...   \n",
       "4639    2/7/17         brief-iradimed corp q4 non-gaap eps $0.11    \n",
       "1094    5/3/16  brief-eqt intends to commence public offering ...   \n",
       "4084   12/4/13  google takes on amazon by cutting cloud servic...   \n",
       "1318  10/22/15  australia waves through news corp buy-in to st...   \n",
       "3922   5/31/12                       text-s&p raises ibm ratings    \n",
       "\n",
       "                                         first_sentence  stock_return  \\\n",
       "1790  Sept 2 General Electric Co's healthcare unit l...       -0.0052   \n",
       "5550  * Q2 earnings per share view $0.55 -- Thomson ...       -0.0014   \n",
       "4639  * Iradimed Corporation announces fourth quarte...       -0.0292   \n",
       "1094  * Intends to commence a registered public offe...       -0.0084   \n",
       "4084  SAN FRANCISCO  Dec 3 Google Inc will lower pri...       -0.0007   \n",
       "1318  SYDNEY  Oct 22 Australia's antitrust regulator...        0.0018   \n",
       "3922  Overview\\t      -- U.S. technology and solutio...       -0.0062   \n",
       "\n",
       "      stock_label                                     text_tokenized  \\\n",
       "1790            0  [ge, 's, 3d, mammography, device, gets, u.s., ...   \n",
       "5550            0  [brief-lamb, weston, reports, fiscal, q2, 2017...   \n",
       "4639            0  [brief-iradimed, corp, q4, non-gaap, eps, $, 0...   \n",
       "1094            0  [brief-eqt, intends, to, commence, public, off...   \n",
       "4084            0  [google, takes, on, amazon, by, cutting, cloud...   \n",
       "1318            1  [australia, waves, through, news, corp, buy-in...   \n",
       "3922            0               [text-s, &, p, raises, ibm, ratings]   \n",
       "\n",
       "                                     text_tokenized_idx  rnn_pred  \n",
       "1790  [2959, 72, 1087, 3408, 3409, 382, 219, 1927, 203]         0  \n",
       "5550      [7077, 7078, 6, 1524, 1805, 1871, 8, 9, 7079]         1  \n",
       "4639                    [6305, 12, 7, 4265, 8, 9, 6306]         1  \n",
       "1094    [2053, 2286, 31, 2287, 14, 15, 16, 472, 20, 18]         0  \n",
       "4084  [2756, 959, 68, 2975, 360, 3660, 1626, 1427, 1...         0  \n",
       "1318  [2122, 2707, 2275, 882, 12, 2708, 31, 2709, 27...         1  \n",
       "3922                       [49, 50, 51, 693, 5288, 213]         0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0, 2959,   72, 1087, 3408, 3409,  382,  219, 1927,  203],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0, 7077, 7078,    6, 1524, 1805, 1871,    8,    9, 7079]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_padded_words[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>stock_label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tokenized_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>518</td>\n",
       "      <td>DIS</td>\n",
       "      <td>Walt Disney Company (The)</td>\n",
       "      <td>10/6/11</td>\n",
       "      <td>wal-mart goes back to basics in holiday toy ai...</td>\n",
       "      <td>NORTH BERGEN  New Jersey Wal-Mart is taking cu...</td>\n",
       "      <td>-0.0018</td>\n",
       "      <td>0</td>\n",
       "      <td>[wal-mart, goes, back, to, basics, in, holiday...</td>\n",
       "      <td>[1154, 1155, 1129, 31, 1156, 27, 1015, 1157, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>5204</td>\n",
       "      <td>JD</td>\n",
       "      <td>JDcom Inc</td>\n",
       "      <td>5/13/15</td>\n",
       "      <td>alibaba rolls out 3-hour delivery service for ...</td>\n",
       "      <td>BEIJING  May 12 Chinese online shopping giant ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>[alibaba, rolls, out, 3-hour, delivery, servic...</td>\n",
       "      <td>[4637, 1026, 126, 6810, 4573, 1427, 92, 1021, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 ticker               company_name     date  \\\n",
       "518          518    DIS  Walt Disney Company (The)  10/6/11   \n",
       "5204        5204     JD                  JDcom Inc  5/13/15   \n",
       "\n",
       "                                               headline  \\\n",
       "518   wal-mart goes back to basics in holiday toy ai...   \n",
       "5204  alibaba rolls out 3-hour delivery service for ...   \n",
       "\n",
       "                                         first_sentence  stock_return  \\\n",
       "518   NORTH BERGEN  New Jersey Wal-Mart is taking cu...       -0.0018   \n",
       "5204  BEIJING  May 12 Chinese online shopping giant ...        0.0000   \n",
       "\n",
       "      stock_label                                     text_tokenized  \\\n",
       "518             0  [wal-mart, goes, back, to, basics, in, holiday...   \n",
       "5204            1  [alibaba, rolls, out, 3-hour, delivery, servic...   \n",
       "\n",
       "                                     text_tokenized_idx  \n",
       "518   [1154, 1155, 1129, 31, 1156, 27, 1015, 1157, 1...  \n",
       "5204  [4637, 1026, 126, 6810, 4573, 1427, 92, 1021, ...  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8415"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "cnn_vocab = sorted(reduce(lambda x, y: x | y, (set(words) for words in train['text_tokenized'])))\n",
    "len(cnn_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3254\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from collections import Counter\n",
    "\n",
    "def word_freq(Xs, num):\n",
    "    all_words = [words.lower() for sentences in train['text_tokenized'] for words in sentences]\n",
    "    sorted_vocab = sorted(dict(Counter(all_words)).items(), key=operator.itemgetter(1))\n",
    "    final_vocab = [k for k,v in sorted_vocab if v>num]\n",
    "    word_idx = dict((c, i + 1) for i, c in enumerate(final_vocab))\n",
    "    return final_vocab, word_idx\n",
    "\n",
    "final_vocab, word_idx = word_freq(train['text_tokenized'],2)\n",
    "vocab_len = len(final_vocab) # Finally we have 3254 words!\n",
    "\n",
    "print(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blood', 'returning', 'authors']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vocab[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1018, 33)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_padded_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(train['headline'])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(train['headline'])\n",
    "x_train_cnn = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6810, 50)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_82 (Embedding)     (None, 33, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 33, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 29, 64)            32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 449       \n",
      "=================================================================\n",
      "Total params: 2,032,513\n",
      "Trainable params: 2,032,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.layers import Convolution1D, Convolution2D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "\n",
    "hidden_size = 500\n",
    "max_length = 33\n",
    "num_steps = 30\n",
    "vocabulary_size = 20000\n",
    "n_class = 1\n",
    "n_word_input_nodes=len(words_lexicon) + 1, #Add one for 0 padding\n",
    "kernel_size = 3\n",
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Embedding(vocabulary_size, 100, input_length=33))\n",
    "model_cnn.add(Dropout(0.2))\n",
    "model_cnn.add(Conv1D(64, 5, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=4))\n",
    "#model_cnn.add(LSTM(100))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#model_cnn = Sequential()\n",
    "#model_cnn.add(Embedding(input_dim=n_word_input_nodes[0],\n",
    "#                     input_length=max_length,\n",
    "#                     output_dim=20, \n",
    "#                     mask_zero=True))\n",
    "#model_cnn.add(Dropout(0.25))\n",
    "#model_cnn.add(Convolution1D(nb_filter=nb_filter,\n",
    "#                        filter_length=filter_length,\n",
    "#                        border_mode='valid',\n",
    "#                        activation='relu',\n",
    "#                        subsample_length=1))\n",
    "#model_cnn.add(Convolution1D(padding=\"same\", kernel_size=3, filters=32))\n",
    "#model_cnn.add(Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[1],\n",
    "#                      border_mode='valid', activation='relu'))\n",
    "#model_cnn.add(GlobalMaxPooling1D())\n",
    "#model_cnn.add(Dense(n_class, activation=\"sigmoid\"))\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6129 samples, validate on 681 samples\n",
      "Epoch 1/5\n",
      "6129/6129 [==============================] - 12s 2ms/step - loss: 0.6859 - acc: 0.5583 - val_loss: 0.6708 - val_acc: 0.6065\n",
      "Epoch 2/5\n",
      "6129/6129 [==============================] - 9s 2ms/step - loss: 0.5270 - acc: 0.7706 - val_loss: 0.5951 - val_acc: 0.6769\n",
      "Epoch 3/5\n",
      "6129/6129 [==============================] - 10s 2ms/step - loss: 0.2613 - acc: 0.8979 - val_loss: 0.6152 - val_acc: 0.7269\n",
      "Epoch 4/5\n",
      "6129/6129 [==============================] - 10s 2ms/step - loss: 0.1306 - acc: 0.9514 - val_loss: 0.6800 - val_acc: 0.7460\n",
      "Epoch 5/5\n",
      "6129/6129 [==============================] - 10s 2ms/step - loss: 0.0844 - acc: 0.9692 - val_loss: 0.7348 - val_acc: 0.7445\n"
     ]
    }
   ],
   "source": [
    "cnn_fit = model_cnn.fit(x = train_padded_words, #y = train['stock_label'],\n",
    "                        y = train_label,\n",
    "                        batch_size=32,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 0s 89us/step\n",
      "Test score: 0.7459681071560603\n",
      "Test accuracy: 0.7445972492746379\n"
     ]
    }
   ],
   "source": [
    "cnn_score = model_cnn.evaluate(test_padded_words, test_label,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('Test score:', cnn_score[0])\n",
    "print('Test accuracy:', cnn_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_pred = model_cnn.predict(test_padded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['cnn_pred'] = cnn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "def label_recode(series):\n",
    "    if series < 0.5 :\n",
    "        return 0\n",
    "    elif series >= 0.5 :\n",
    "        return 1\n",
    "    \n",
    "test['cnn_pred'] = test['cnn_pred'].apply(label_recode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.66\n",
      "Recall Score: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, recall_score\n",
    "\n",
    "cnn_precision = average_precision_score(test['stock_label'], test['cnn_pred'])\n",
    "cnn_recall = recall_score(test['stock_label'], test['cnn_pred'], average=\"macro\")\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      cnn_precision))\n",
    "print('Recall Score: {0:0.2f}'.format(\n",
    "      cnn_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>stock_label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tokenized_idx</th>\n",
       "      <th>rnn_pred</th>\n",
       "      <th>cnn_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>1790</td>\n",
       "      <td>GEK</td>\n",
       "      <td>General Electric Capital Corporation</td>\n",
       "      <td>9/4/14</td>\n",
       "      <td>ge's 3d mammography device gets u.s. fda appro...</td>\n",
       "      <td>Sept 2 General Electric Co's healthcare unit l...</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0</td>\n",
       "      <td>[ge, 's, 3d, mammography, device, gets, u.s., ...</td>\n",
       "      <td>[2959, 72, 1087, 3408, 3409, 382, 219, 1927, 203]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>5550</td>\n",
       "      <td>LW</td>\n",
       "      <td>Lamb Weston Holdings Inc</td>\n",
       "      <td>1/11/17</td>\n",
       "      <td>brief-lamb weston reports fiscal q2 2017 eps $...</td>\n",
       "      <td>* Q2 earnings per share view $0.55 -- Thomson ...</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0</td>\n",
       "      <td>[brief-lamb, weston, reports, fiscal, q2, 2017...</td>\n",
       "      <td>[7077, 7078, 6, 1524, 1805, 1871, 8, 9, 7079]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>4639</td>\n",
       "      <td>IRMD</td>\n",
       "      <td>iRadimed Corporation</td>\n",
       "      <td>2/7/17</td>\n",
       "      <td>brief-iradimed corp q4 non-gaap eps $0.11</td>\n",
       "      <td>* Iradimed Corporation announces fourth quarte...</td>\n",
       "      <td>-0.0292</td>\n",
       "      <td>0</td>\n",
       "      <td>[brief-iradimed, corp, q4, non-gaap, eps, $, 0...</td>\n",
       "      <td>[6305, 12, 7, 4265, 8, 9, 6306]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1094</td>\n",
       "      <td>EQT</td>\n",
       "      <td>EQT Corporation</td>\n",
       "      <td>5/3/16</td>\n",
       "      <td>brief-eqt intends to commence public offering ...</td>\n",
       "      <td>* Intends to commence a registered public offe...</td>\n",
       "      <td>-0.0084</td>\n",
       "      <td>0</td>\n",
       "      <td>[brief-eqt, intends, to, commence, public, off...</td>\n",
       "      <td>[2053, 2286, 31, 2287, 14, 15, 16, 472, 20, 18]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>4084</td>\n",
       "      <td>IBM</td>\n",
       "      <td>International Business Machines Corporation</td>\n",
       "      <td>12/4/13</td>\n",
       "      <td>google takes on amazon by cutting cloud servic...</td>\n",
       "      <td>SAN FRANCISCO  Dec 3 Google Inc will lower pri...</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0</td>\n",
       "      <td>[google, takes, on, amazon, by, cutting, cloud...</td>\n",
       "      <td>[2756, 959, 68, 2975, 360, 3660, 1626, 1427, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1318</td>\n",
       "      <td>FOX</td>\n",
       "      <td>Twenty-First Century Fox Inc</td>\n",
       "      <td>10/22/15</td>\n",
       "      <td>australia waves through news corp buy-in to st...</td>\n",
       "      <td>SYDNEY  Oct 22 Australia's antitrust regulator...</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1</td>\n",
       "      <td>[australia, waves, through, news, corp, buy-in...</td>\n",
       "      <td>[2122, 2707, 2275, 882, 12, 2708, 31, 2709, 27...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>3922</td>\n",
       "      <td>IBM</td>\n",
       "      <td>International Business Machines Corporation</td>\n",
       "      <td>5/31/12</td>\n",
       "      <td>text-s&amp;p raises ibm ratings</td>\n",
       "      <td>Overview\\t      -- U.S. technology and solutio...</td>\n",
       "      <td>-0.0062</td>\n",
       "      <td>0</td>\n",
       "      <td>[text-s, &amp;, p, raises, ibm, ratings]</td>\n",
       "      <td>[49, 50, 51, 693, 5288, 213]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 ticker                                 company_name  \\\n",
       "1790        1790    GEK         General Electric Capital Corporation   \n",
       "5550        5550     LW                     Lamb Weston Holdings Inc   \n",
       "4639        4639   IRMD                         iRadimed Corporation   \n",
       "1094        1094    EQT                              EQT Corporation   \n",
       "4084        4084    IBM  International Business Machines Corporation   \n",
       "1318        1318    FOX                 Twenty-First Century Fox Inc   \n",
       "3922        3922    IBM  International Business Machines Corporation   \n",
       "\n",
       "          date                                           headline  \\\n",
       "1790    9/4/14  ge's 3d mammography device gets u.s. fda appro...   \n",
       "5550   1/11/17  brief-lamb weston reports fiscal q2 2017 eps $...   \n",
       "4639    2/7/17         brief-iradimed corp q4 non-gaap eps $0.11    \n",
       "1094    5/3/16  brief-eqt intends to commence public offering ...   \n",
       "4084   12/4/13  google takes on amazon by cutting cloud servic...   \n",
       "1318  10/22/15  australia waves through news corp buy-in to st...   \n",
       "3922   5/31/12                       text-s&p raises ibm ratings    \n",
       "\n",
       "                                         first_sentence  stock_return  \\\n",
       "1790  Sept 2 General Electric Co's healthcare unit l...       -0.0052   \n",
       "5550  * Q2 earnings per share view $0.55 -- Thomson ...       -0.0014   \n",
       "4639  * Iradimed Corporation announces fourth quarte...       -0.0292   \n",
       "1094  * Intends to commence a registered public offe...       -0.0084   \n",
       "4084  SAN FRANCISCO  Dec 3 Google Inc will lower pri...       -0.0007   \n",
       "1318  SYDNEY  Oct 22 Australia's antitrust regulator...        0.0018   \n",
       "3922  Overview\\t      -- U.S. technology and solutio...       -0.0062   \n",
       "\n",
       "      stock_label                                     text_tokenized  \\\n",
       "1790            0  [ge, 's, 3d, mammography, device, gets, u.s., ...   \n",
       "5550            0  [brief-lamb, weston, reports, fiscal, q2, 2017...   \n",
       "4639            0  [brief-iradimed, corp, q4, non-gaap, eps, $, 0...   \n",
       "1094            0  [brief-eqt, intends, to, commence, public, off...   \n",
       "4084            0  [google, takes, on, amazon, by, cutting, cloud...   \n",
       "1318            1  [australia, waves, through, news, corp, buy-in...   \n",
       "3922            0               [text-s, &, p, raises, ibm, ratings]   \n",
       "\n",
       "                                     text_tokenized_idx  rnn_pred  cnn_pred  \n",
       "1790  [2959, 72, 1087, 3408, 3409, 382, 219, 1927, 203]         0         0  \n",
       "5550      [7077, 7078, 6, 1524, 1805, 1871, 8, 9, 7079]         1         1  \n",
       "4639                    [6305, 12, 7, 4265, 8, 9, 6306]         1         1  \n",
       "1094    [2053, 2286, 31, 2287, 14, 15, 16, 472, 20, 18]         0         0  \n",
       "4084  [2756, 959, 68, 2975, 360, 3660, 1626, 1427, 1...         0         0  \n",
       "1318  [2122, 2707, 2275, 882, 12, 2708, 31, 2709, 27...         1         0  \n",
       "3922                       [49, 50, 51, 693, 5288, 213]         0         1  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: RNN+CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_84 (Embedding)     (None, 33, 100)           2000000   \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 33, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 29, 64)            32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_19 (SimpleRNN)    (None, 100)               16500     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,048,665\n",
      "Trainable params: 2,048,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.layers import Convolution1D, Convolution2D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam, rmsprop\n",
    "\n",
    "hidden_size = 500\n",
    "max_length = 33\n",
    "num_steps = 30\n",
    "vocabulary_size = 20000\n",
    "n_class = 1\n",
    "n_word_input_nodes=len(words_lexicon) + 1, #Add one for 0 padding\n",
    "kernel_size = 3\n",
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Embedding(vocabulary_size, 100, input_length=33))\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(Conv1D(64, 5, activation='relu'))\n",
    "model_3.add(MaxPooling1D(pool_size=4))\n",
    "model_3.add(SimpleRNN(100, return_sequences=False))\n",
    "model_3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model_3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6129 samples, validate on 681 samples\n",
      "Epoch 1/5\n",
      "6129/6129 [==============================] - 13s 2ms/step - loss: 0.6726 - acc: 0.5771 - val_loss: 0.6347 - val_acc: 0.6667\n",
      "Epoch 2/5\n",
      "6129/6129 [==============================] - 11s 2ms/step - loss: 0.3893 - acc: 0.8305 - val_loss: 0.5551 - val_acc: 0.7327\n",
      "Epoch 3/5\n",
      "6129/6129 [==============================] - 12s 2ms/step - loss: 0.1417 - acc: 0.9480 - val_loss: 0.7230 - val_acc: 0.7357\n",
      "Epoch 4/5\n",
      "6129/6129 [==============================] - 10s 2ms/step - loss: 0.0833 - acc: 0.9736 - val_loss: 0.7308 - val_acc: 0.7342\n",
      "Epoch 5/5\n",
      "6129/6129 [==============================] - 11s 2ms/step - loss: 0.0702 - acc: 0.9745 - val_loss: 0.7156 - val_acc: 0.7445\n"
     ]
    }
   ],
   "source": [
    "model_3_fit = model_3.fit(x = train_padded_words, #y = train['stock_label'],\n",
    "                        y = train_label,\n",
    "                        batch_size=32,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1018/1018 [==============================] - 0s 120us/step\n",
      "Test score: 0.745201237309424\n",
      "Test accuracy: 0.7328094309580115\n"
     ]
    }
   ],
   "source": [
    "model_3_score = model_3.evaluate(test_padded_words, test_label,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('Test score:', model_3_score[0])\n",
    "print('Test accuracy:', model_3_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_3_pred = model_3.predict(test_padded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['model_3_pred'] = model_3_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuixin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "def label_recode(series):\n",
    "    if series < 0.5 :\n",
    "        return 0\n",
    "    elif series >= 0.5 :\n",
    "        return 1\n",
    "    \n",
    "test['model_3_pred'] = test['model_3_pred'].apply(label_recode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score: 0.65\n",
      "Recall Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, recall_score\n",
    "\n",
    "model_3_precision = average_precision_score(test['stock_label'], test['model_3_pred'])\n",
    "model_3_recall = recall_score(test['stock_label'], test['model_3_pred'], average=\"macro\")\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      model_3_precision))\n",
    "print('Recall Score: {0:0.2f}'.format(\n",
    "      model_3_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>first_sentence</th>\n",
       "      <th>stock_return</th>\n",
       "      <th>stock_label</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>text_tokenized_idx</th>\n",
       "      <th>rnn_pred</th>\n",
       "      <th>cnn_pred</th>\n",
       "      <th>model_3_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>1790</td>\n",
       "      <td>GEK</td>\n",
       "      <td>General Electric Capital Corporation</td>\n",
       "      <td>9/4/14</td>\n",
       "      <td>ge's 3d mammography device gets u.s. fda appro...</td>\n",
       "      <td>Sept 2 General Electric Co's healthcare unit l...</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0</td>\n",
       "      <td>[ge, 's, 3d, mammography, device, gets, u.s., ...</td>\n",
       "      <td>[2959, 72, 1087, 3408, 3409, 382, 219, 1927, 203]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>5550</td>\n",
       "      <td>LW</td>\n",
       "      <td>Lamb Weston Holdings Inc</td>\n",
       "      <td>1/11/17</td>\n",
       "      <td>brief-lamb weston reports fiscal q2 2017 eps $...</td>\n",
       "      <td>* Q2 earnings per share view $0.55 -- Thomson ...</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>0</td>\n",
       "      <td>[brief-lamb, weston, reports, fiscal, q2, 2017...</td>\n",
       "      <td>[7077, 7078, 6, 1524, 1805, 1871, 8, 9, 7079]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>4639</td>\n",
       "      <td>IRMD</td>\n",
       "      <td>iRadimed Corporation</td>\n",
       "      <td>2/7/17</td>\n",
       "      <td>brief-iradimed corp q4 non-gaap eps $0.11</td>\n",
       "      <td>* Iradimed Corporation announces fourth quarte...</td>\n",
       "      <td>-0.0292</td>\n",
       "      <td>0</td>\n",
       "      <td>[brief-iradimed, corp, q4, non-gaap, eps, $, 0...</td>\n",
       "      <td>[6305, 12, 7, 4265, 8, 9, 6306]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>1094</td>\n",
       "      <td>EQT</td>\n",
       "      <td>EQT Corporation</td>\n",
       "      <td>5/3/16</td>\n",
       "      <td>brief-eqt intends to commence public offering ...</td>\n",
       "      <td>* Intends to commence a registered public offe...</td>\n",
       "      <td>-0.0084</td>\n",
       "      <td>0</td>\n",
       "      <td>[brief-eqt, intends, to, commence, public, off...</td>\n",
       "      <td>[2053, 2286, 31, 2287, 14, 15, 16, 472, 20, 18]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>4084</td>\n",
       "      <td>IBM</td>\n",
       "      <td>International Business Machines Corporation</td>\n",
       "      <td>12/4/13</td>\n",
       "      <td>google takes on amazon by cutting cloud servic...</td>\n",
       "      <td>SAN FRANCISCO  Dec 3 Google Inc will lower pri...</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>0</td>\n",
       "      <td>[google, takes, on, amazon, by, cutting, cloud...</td>\n",
       "      <td>[2756, 959, 68, 2975, 360, 3660, 1626, 1427, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>1318</td>\n",
       "      <td>FOX</td>\n",
       "      <td>Twenty-First Century Fox Inc</td>\n",
       "      <td>10/22/15</td>\n",
       "      <td>australia waves through news corp buy-in to st...</td>\n",
       "      <td>SYDNEY  Oct 22 Australia's antitrust regulator...</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1</td>\n",
       "      <td>[australia, waves, through, news, corp, buy-in...</td>\n",
       "      <td>[2122, 2707, 2275, 882, 12, 2708, 31, 2709, 27...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>3922</td>\n",
       "      <td>IBM</td>\n",
       "      <td>International Business Machines Corporation</td>\n",
       "      <td>5/31/12</td>\n",
       "      <td>text-s&amp;p raises ibm ratings</td>\n",
       "      <td>Overview\\t      -- U.S. technology and solutio...</td>\n",
       "      <td>-0.0062</td>\n",
       "      <td>0</td>\n",
       "      <td>[text-s, &amp;, p, raises, ibm, ratings]</td>\n",
       "      <td>[49, 50, 51, 693, 5288, 213]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>3238</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>4/17/15</td>\n",
       "      <td>yahoo and facebook shares outperform google in...</td>\n",
       "      <td>LONDON The Frankfurt-listed shares of Internet...</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>0</td>\n",
       "      <td>[yahoo, and, facebook, shares, outperform, goo...</td>\n",
       "      <td>[1117, 59, 1056, 18, 4999, 2756, 27, 5000]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>4166</td>\n",
       "      <td>IBM</td>\n",
       "      <td>International Business Machines Corporation</td>\n",
       "      <td>5/15/14</td>\n",
       "      <td>ibm expects hardware business to stabilize in ...</td>\n",
       "      <td>NEW YORK  May 14 International Business Machin...</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0</td>\n",
       "      <td>[ibm, expects, hardware, business, to, stabili...</td>\n",
       "      <td>[5288, 1484, 5747, 990, 31, 5898, 27, 574, 264...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>JCP</td>\n",
       "      <td>JC Penney Company Inc Holding Company</td>\n",
       "      <td>8/14/13</td>\n",
       "      <td>bad jc penney bet calls ackman's retail acumen...</td>\n",
       "      <td>BOSTON  Aug 13 Billionaire investor William Ac...</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>1</td>\n",
       "      <td>[bad, jc, penney, bet, calls, ackman, 's, reta...</td>\n",
       "      <td>[4410, 6438, 3025, 3422, 278, 6442, 72, 3154, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>6742</td>\n",
       "      <td>MCD</td>\n",
       "      <td>McDonald&amp;#39;s Corporation</td>\n",
       "      <td>8/23/11</td>\n",
       "      <td>market turmoil shakes up investor options</td>\n",
       "      <td>THE ISSUE: Three weeks of roller-coaster equit...</td>\n",
       "      <td>-0.0137</td>\n",
       "      <td>0</td>\n",
       "      <td>[market, turmoil, shakes, up, investor, options]</td>\n",
       "      <td>[937, 6383, 2535, 102, 762, 3587]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6728</th>\n",
       "      <td>6728</td>\n",
       "      <td>MCD</td>\n",
       "      <td>McDonald&amp;#39;s Corporation</td>\n",
       "      <td>7/29/11</td>\n",
       "      <td>dunkin' brands shares soar in stock market debut</td>\n",
       "      <td>LOS ANGELES Investors hungry for restaurant gr...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1</td>\n",
       "      <td>[dunkin, ', brands, shares, soar, in, stock, m...</td>\n",
       "      <td>[8059, 81, 716, 18, 117, 27, 303, 937, 3388]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>1270</td>\n",
       "      <td>FOX</td>\n",
       "      <td>Twenty-First Century Fox Inc</td>\n",
       "      <td>3/20/15</td>\n",
       "      <td>corrected-update 2-news corp expands stake in ...</td>\n",
       "      <td>SYDNEY/DUBLIN  March 19 News Corp  increased i...</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>1</td>\n",
       "      <td>[corrected-update, 2-news, corp, expands, stak...</td>\n",
       "      <td>[530, 2631, 12, 1001, 26, 27, 2122, 72, 2632, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>138</td>\n",
       "      <td>CZR</td>\n",
       "      <td>Caesars Entertainment Corporation</td>\n",
       "      <td>3/19/15</td>\n",
       "      <td>caesars warns creditor lawsuits may endanger '...</td>\n",
       "      <td>Casino company Caesars Entertainment Corp   wh...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>1</td>\n",
       "      <td>[caesars, warns, creditor, lawsuits, may, enda...</td>\n",
       "      <td>[53, 406, 407, 243, 408, 409, 410, 411, 81, 412]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3394</th>\n",
       "      <td>3394</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>8/7/15</td>\n",
       "      <td>internet firms to be subject to new cybersecur...</td>\n",
       "      <td>BRUSSELS Internet firms such as Cisco   Google...</td>\n",
       "      <td>-0.0058</td>\n",
       "      <td>0</td>\n",
       "      <td>[internet, firms, to, be, subject, to, new, cy...</td>\n",
       "      <td>[139, 680, 31, 598, 5153, 31, 113, 4814, 1090,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>CZR</td>\n",
       "      <td>Caesars Entertainment Corporation</td>\n",
       "      <td>1/15/15</td>\n",
       "      <td>caesars' unit to file for bankruptcy thursday ...</td>\n",
       "      <td>Jan 14 Caesars Entertainment Corp's  operating...</td>\n",
       "      <td>-0.0566</td>\n",
       "      <td>0</td>\n",
       "      <td>[caesars, ', unit, to, file, for, bankruptcy, ...</td>\n",
       "      <td>[53, 81, 76, 31, 323, 92, 325, 338, 27, 339]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>6993</td>\n",
       "      <td>MCD</td>\n",
       "      <td>McDonald&amp;#39;s Corporation</td>\n",
       "      <td>3/19/14</td>\n",
       "      <td>new york mcdonald's owner to pay $500 000 to s...</td>\n",
       "      <td>The owner of seven franchised McDonald's resta...</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>0</td>\n",
       "      <td>[new, york, mcdonald, 's, owner, to, pay, $, 5...</td>\n",
       "      <td>[113, 455, 8051, 72, 2200, 31, 465, 9, 926, 18...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>741</td>\n",
       "      <td>DIS</td>\n",
       "      <td>Walt Disney Company (The)</td>\n",
       "      <td>12/24/13</td>\n",
       "      <td>disney ceo gets 15 pct pay cut despite \"strong...</td>\n",
       "      <td>Dec 23 Walt Disney Co CEO Bob Iger's compensat...</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>1</td>\n",
       "      <td>[disney, ceo, gets, 15, pct, pay, cut, despite...</td>\n",
       "      <td>[742, 223, 382, 1008, 24, 465, 1182, 930, 413,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>1292</td>\n",
       "      <td>FOX</td>\n",
       "      <td>Twenty-First Century Fox Inc</td>\n",
       "      <td>6/19/15</td>\n",
       "      <td>update 1-news corp to reorganize  cut jobs in ...</td>\n",
       "      <td>June 18 News Corp  owner of the Wall Street Jo...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1</td>\n",
       "      <td>[update, 1-news, corp, to, reorganize, cut, jo...</td>\n",
       "      <td>[110, 2650, 12, 31, 2673, 1182, 948, 27, 882, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1648</td>\n",
       "      <td>GEK</td>\n",
       "      <td>General Electric Capital Corporation</td>\n",
       "      <td>5/8/14</td>\n",
       "      <td>update 5-siemens chief unveils overhaul  won't...</td>\n",
       "      <td>* Operating profit falls short of consensus on...</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>[update, 5-siemens, chief, unveils, overhaul, ...</td>\n",
       "      <td>[110, 3256, 999, 2528, 1255, 463, 464, 598, 32...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>4205</td>\n",
       "      <td>IBM</td>\n",
       "      <td>International Business Machines Corporation</td>\n",
       "      <td>7/18/14</td>\n",
       "      <td>update 3-ibm software sales weaker than expect...</td>\n",
       "      <td>(Adds details on individual sectors  buybacks ...</td>\n",
       "      <td>-0.0102</td>\n",
       "      <td>0</td>\n",
       "      <td>[update, 3-ibm, software, sales, weaker, than,...</td>\n",
       "      <td>[110, 5626, 803, 833, 2499, 1072, 1609, 27, 49...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>1702</td>\n",
       "      <td>GEK</td>\n",
       "      <td>General Electric Capital Corporation</td>\n",
       "      <td>6/17/14</td>\n",
       "      <td>factbox: details of siemens/mitsubishi energy ...</td>\n",
       "      <td>Germany's Siemens and Japan's Mitsubishi Heavy...</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>[factbox, :, details, of, siemens/mitsubishi, ...</td>\n",
       "      <td>[1038, 86, 317, 16, 3312, 3007, 144, 448, 3194]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6235</th>\n",
       "      <td>6235</td>\n",
       "      <td>LYG</td>\n",
       "      <td>Lloyds Banking Group Plc</td>\n",
       "      <td>10/29/14</td>\n",
       "      <td>lloyds remains confident of paying 2014 dividend</td>\n",
       "      <td>LONDON Lloyds Banking Group  remains hopeful o...</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>1</td>\n",
       "      <td>[lloyds, remains, confident, of, paying, 2014,...</td>\n",
       "      <td>[7101, 3696, 3505, 16, 1073, 574, 1175]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>2654</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>4/25/14</td>\n",
       "      <td>apple  google agree to settle antitrust lawsui...</td>\n",
       "      <td>SAN FRANCISCO  April 24 Four major tech compan...</td>\n",
       "      <td>-0.0133</td>\n",
       "      <td>0</td>\n",
       "      <td>[apple, google, agree, to, settle, antitrust, ...</td>\n",
       "      <td>[957, 2756, 2460, 31, 2751, 2694, 440, 244, 43...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>CZR</td>\n",
       "      <td>Caesars Entertainment Corporation</td>\n",
       "      <td>10/9/15</td>\n",
       "      <td>caesars tries to woo strengthened creditors wi...</td>\n",
       "      <td>CHICAGO Caesars Entertainment Corp's  bankrupt...</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>1</td>\n",
       "      <td>[caesars, tries, to, woo, strengthened, credit...</td>\n",
       "      <td>[53, 481, 31, 482, 483, 252, 448, 113, 318]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 ticker                                 company_name  \\\n",
       "1790        1790    GEK         General Electric Capital Corporation   \n",
       "5550        5550     LW                     Lamb Weston Holdings Inc   \n",
       "4639        4639   IRMD                         iRadimed Corporation   \n",
       "1094        1094    EQT                              EQT Corporation   \n",
       "4084        4084    IBM  International Business Machines Corporation   \n",
       "1318        1318    FOX                 Twenty-First Century Fox Inc   \n",
       "3922        3922    IBM  International Business Machines Corporation   \n",
       "3238        3238  GOOGL                                 Alphabet Inc   \n",
       "4166        4166    IBM  International Business Machines Corporation   \n",
       "4997        4997    JCP        JC Penney Company Inc Holding Company   \n",
       "6742        6742    MCD                   McDonald&#39;s Corporation   \n",
       "6728        6728    MCD                   McDonald&#39;s Corporation   \n",
       "1270        1270    FOX                 Twenty-First Century Fox Inc   \n",
       "138          138    CZR            Caesars Entertainment Corporation   \n",
       "3394        3394  GOOGL                                 Alphabet Inc   \n",
       "95            95    CZR            Caesars Entertainment Corporation   \n",
       "6993        6993    MCD                   McDonald&#39;s Corporation   \n",
       "741          741    DIS                    Walt Disney Company (The)   \n",
       "1292        1292    FOX                 Twenty-First Century Fox Inc   \n",
       "1648        1648    GEK         General Electric Capital Corporation   \n",
       "4205        4205    IBM  International Business Machines Corporation   \n",
       "1702        1702    GEK         General Electric Capital Corporation   \n",
       "6235        6235    LYG                     Lloyds Banking Group Plc   \n",
       "2654        2654  GOOGL                                 Alphabet Inc   \n",
       "195          195    CZR            Caesars Entertainment Corporation   \n",
       "\n",
       "          date                                           headline  \\\n",
       "1790    9/4/14  ge's 3d mammography device gets u.s. fda appro...   \n",
       "5550   1/11/17  brief-lamb weston reports fiscal q2 2017 eps $...   \n",
       "4639    2/7/17         brief-iradimed corp q4 non-gaap eps $0.11    \n",
       "1094    5/3/16  brief-eqt intends to commence public offering ...   \n",
       "4084   12/4/13  google takes on amazon by cutting cloud servic...   \n",
       "1318  10/22/15  australia waves through news corp buy-in to st...   \n",
       "3922   5/31/12                       text-s&p raises ibm ratings    \n",
       "3238   4/17/15  yahoo and facebook shares outperform google in...   \n",
       "4166   5/15/14  ibm expects hardware business to stabilize in ...   \n",
       "4997   8/14/13  bad jc penney bet calls ackman's retail acumen...   \n",
       "6742   8/23/11         market turmoil shakes up investor options    \n",
       "6728   7/29/11  dunkin' brands shares soar in stock market debut    \n",
       "1270   3/20/15  corrected-update 2-news corp expands stake in ...   \n",
       "138    3/19/15  caesars warns creditor lawsuits may endanger '...   \n",
       "3394    8/7/15  internet firms to be subject to new cybersecur...   \n",
       "95     1/15/15  caesars' unit to file for bankruptcy thursday ...   \n",
       "6993   3/19/14  new york mcdonald's owner to pay $500 000 to s...   \n",
       "741   12/24/13  disney ceo gets 15 pct pay cut despite \"strong...   \n",
       "1292   6/19/15  update 1-news corp to reorganize  cut jobs in ...   \n",
       "1648    5/8/14  update 5-siemens chief unveils overhaul  won't...   \n",
       "4205   7/18/14  update 3-ibm software sales weaker than expect...   \n",
       "1702   6/17/14  factbox: details of siemens/mitsubishi energy ...   \n",
       "6235  10/29/14  lloyds remains confident of paying 2014 dividend    \n",
       "2654   4/25/14  apple  google agree to settle antitrust lawsui...   \n",
       "195    10/9/15  caesars tries to woo strengthened creditors wi...   \n",
       "\n",
       "                                         first_sentence  stock_return  \\\n",
       "1790  Sept 2 General Electric Co's healthcare unit l...       -0.0052   \n",
       "5550  * Q2 earnings per share view $0.55 -- Thomson ...       -0.0014   \n",
       "4639  * Iradimed Corporation announces fourth quarte...       -0.0292   \n",
       "1094  * Intends to commence a registered public offe...       -0.0084   \n",
       "4084  SAN FRANCISCO  Dec 3 Google Inc will lower pri...       -0.0007   \n",
       "1318  SYDNEY  Oct 22 Australia's antitrust regulator...        0.0018   \n",
       "3922  Overview\\t      -- U.S. technology and solutio...       -0.0062   \n",
       "3238  LONDON The Frankfurt-listed shares of Internet...       -0.0087   \n",
       "4166  NEW YORK  May 14 International Business Machin...       -0.0027   \n",
       "4997  BOSTON  Aug 13 Billionaire investor William Ac...        0.0385   \n",
       "6742  THE ISSUE: Three weeks of roller-coaster equit...       -0.0137   \n",
       "6728  LOS ANGELES Investors hungry for restaurant gr...        0.0031   \n",
       "1270  SYDNEY/DUBLIN  March 19 News Corp  increased i...        0.0151   \n",
       "138   Casino company Caesars Entertainment Corp   wh...        0.0241   \n",
       "3394  BRUSSELS Internet firms such as Cisco   Google...       -0.0058   \n",
       "95    Jan 14 Caesars Entertainment Corp's  operating...       -0.0566   \n",
       "6993  The owner of seven franchised McDonald's resta...       -0.0063   \n",
       "741   Dec 23 Walt Disney Co CEO Bob Iger's compensat...        0.0048   \n",
       "1292  June 18 News Corp  owner of the Wall Street Jo...        0.0031   \n",
       "1648  * Operating profit falls short of consensus on...       -0.0001   \n",
       "4205  (Adds details on individual sectors  buybacks ...       -0.0102   \n",
       "1702  Germany's Siemens and Japan's Mitsubishi Heavy...       -0.0012   \n",
       "6235  LONDON Lloyds Banking Group  remains hopeful o...        0.0014   \n",
       "2654  SAN FRANCISCO  April 24 Four major tech compan...       -0.0133   \n",
       "195   CHICAGO Caesars Entertainment Corp's  bankrupt...        0.0055   \n",
       "\n",
       "      stock_label                                     text_tokenized  \\\n",
       "1790            0  [ge, 's, 3d, mammography, device, gets, u.s., ...   \n",
       "5550            0  [brief-lamb, weston, reports, fiscal, q2, 2017...   \n",
       "4639            0  [brief-iradimed, corp, q4, non-gaap, eps, $, 0...   \n",
       "1094            0  [brief-eqt, intends, to, commence, public, off...   \n",
       "4084            0  [google, takes, on, amazon, by, cutting, cloud...   \n",
       "1318            1  [australia, waves, through, news, corp, buy-in...   \n",
       "3922            0               [text-s, &, p, raises, ibm, ratings]   \n",
       "3238            0  [yahoo, and, facebook, shares, outperform, goo...   \n",
       "4166            0  [ibm, expects, hardware, business, to, stabili...   \n",
       "4997            1  [bad, jc, penney, bet, calls, ackman, 's, reta...   \n",
       "6742            0   [market, turmoil, shakes, up, investor, options]   \n",
       "6728            1  [dunkin, ', brands, shares, soar, in, stock, m...   \n",
       "1270            1  [corrected-update, 2-news, corp, expands, stak...   \n",
       "138             1  [caesars, warns, creditor, lawsuits, may, enda...   \n",
       "3394            0  [internet, firms, to, be, subject, to, new, cy...   \n",
       "95              0  [caesars, ', unit, to, file, for, bankruptcy, ...   \n",
       "6993            0  [new, york, mcdonald, 's, owner, to, pay, $, 5...   \n",
       "741             1  [disney, ceo, gets, 15, pct, pay, cut, despite...   \n",
       "1292            1  [update, 1-news, corp, to, reorganize, cut, jo...   \n",
       "1648            0  [update, 5-siemens, chief, unveils, overhaul, ...   \n",
       "4205            0  [update, 3-ibm, software, sales, weaker, than,...   \n",
       "1702            0  [factbox, :, details, of, siemens/mitsubishi, ...   \n",
       "6235            1  [lloyds, remains, confident, of, paying, 2014,...   \n",
       "2654            0  [apple, google, agree, to, settle, antitrust, ...   \n",
       "195             1  [caesars, tries, to, woo, strengthened, credit...   \n",
       "\n",
       "                                     text_tokenized_idx  rnn_pred  cnn_pred  \\\n",
       "1790  [2959, 72, 1087, 3408, 3409, 382, 219, 1927, 203]         0         0   \n",
       "5550      [7077, 7078, 6, 1524, 1805, 1871, 8, 9, 7079]         1         1   \n",
       "4639                    [6305, 12, 7, 4265, 8, 9, 6306]         1         1   \n",
       "1094    [2053, 2286, 31, 2287, 14, 15, 16, 472, 20, 18]         0         0   \n",
       "4084  [2756, 959, 68, 2975, 360, 3660, 1626, 1427, 1...         0         0   \n",
       "1318  [2122, 2707, 2275, 882, 12, 2708, 31, 2709, 27...         1         0   \n",
       "3922                       [49, 50, 51, 693, 5288, 213]         0         1   \n",
       "3238         [1117, 59, 1056, 18, 4999, 2756, 27, 5000]         0         0   \n",
       "4166  [5288, 1484, 5747, 990, 31, 5898, 27, 574, 264...         0         0   \n",
       "4997  [4410, 6438, 3025, 3422, 278, 6442, 72, 3154, ...         0         0   \n",
       "6742                  [937, 6383, 2535, 102, 762, 3587]         1         1   \n",
       "6728       [8059, 81, 716, 18, 117, 27, 303, 937, 3388]         0         0   \n",
       "1270  [530, 2631, 12, 1001, 26, 27, 2122, 72, 2632, ...         1         1   \n",
       "138    [53, 406, 407, 243, 408, 409, 410, 411, 81, 412]         1         1   \n",
       "3394  [139, 680, 31, 598, 5153, 31, 113, 4814, 1090,...         0         0   \n",
       "95         [53, 81, 76, 31, 323, 92, 325, 338, 27, 339]         0         0   \n",
       "6993  [113, 455, 8051, 72, 2200, 31, 465, 9, 926, 18...         0         0   \n",
       "741   [742, 223, 382, 1008, 24, 465, 1182, 930, 413,...         0         0   \n",
       "1292  [110, 2650, 12, 31, 2673, 1182, 948, 27, 882, ...         1         1   \n",
       "1648  [110, 3256, 999, 2528, 1255, 463, 464, 598, 32...         0         0   \n",
       "4205  [110, 5626, 803, 833, 2499, 1072, 1609, 27, 49...         0         0   \n",
       "1702    [1038, 86, 317, 16, 3312, 3007, 144, 448, 3194]         1         1   \n",
       "6235            [7101, 3696, 3505, 16, 1073, 574, 1175]         1         1   \n",
       "2654  [957, 2756, 2460, 31, 2751, 2694, 440, 244, 43...         0         1   \n",
       "195         [53, 481, 31, 482, 483, 252, 448, 113, 318]         1         1   \n",
       "\n",
       "      model_3_pred  \n",
       "1790             0  \n",
       "5550             1  \n",
       "4639             1  \n",
       "1094             0  \n",
       "4084             0  \n",
       "1318             0  \n",
       "3922             1  \n",
       "3238             0  \n",
       "4166             0  \n",
       "4997             0  \n",
       "6742             1  \n",
       "6728             0  \n",
       "1270             1  \n",
       "138              1  \n",
       "3394             0  \n",
       "95               0  \n",
       "6993             0  \n",
       "741              0  \n",
       "1292             1  \n",
       "1648             0  \n",
       "4205             0  \n",
       "1702             1  \n",
       "6235             1  \n",
       "2654             0  \n",
       "195              1  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Model    </td><td>Accuracy</td><td>Precision</td><td>Recall</td><td>News Content</td><td>Actual Stock Return</td><td>Predicted Stock Return</td></tr>\n",
       "<tr><td>RNN      </td><td>0.6906  </td><td>0.61     </td><td>0.69  </td><td>195    caesars tries to woo strengthened creditors with new plan \n",
       "Name: headline, dtype: object             </td><td>0                  </td><td>0                     </td></tr>\n",
       "<tr><td>CNN      </td><td>0.7445  </td><td>0.66     </td><td>0.75  </td><td>195    caesars tries to woo strengthened creditors with new plan \n",
       "Name: headline, dtype: object             </td><td>0                  </td><td>1                     </td></tr>\n",
       "<tr><td>RNN + CNN</td><td>0.7328  </td><td>0.65     </td><td>0.73  </td><td>195    caesars tries to woo strengthened creditors with new plan \n",
       "Name: headline, dtype: object             </td><td>0                  </td><td>0                     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "example_1 = [[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"News Content\", \"Actual Stock Return\", \"Predicted Stock Return\"],\n",
    "            [\"RNN\", \"0.6906\", \"0.61\", \"0.69\", test['headline'][24:25], \"0\", \"0\"],\n",
    "            [\"CNN\", \"0.7445\", \"0.66\", \"0.75\", test['headline'][24:25], \"0\", \"1\"],\n",
    "            [\"RNN + CNN\", \"0.7328\", \"0.65\", \"0.73\", test['headline'][24:25], \"0\", \"0\"]\n",
    "    \n",
    "]\n",
    "\n",
    "display(HTML(tabulate.tabulate(example_1, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Model    </td><td>Accuracy</td><td>Precision</td><td>Recall</td><td>News Content</td><td>Actual Stock Return</td><td>Predicted Stock Return</td></tr>\n",
       "<tr><td>RNN      </td><td>0.6906  </td><td>0.61     </td><td>0.69  </td><td>3922    text-s&p raises ibm ratings \n",
       "Name: headline, dtype: object             </td><td>0                  </td><td>0                     </td></tr>\n",
       "<tr><td>CNN      </td><td>0.7445  </td><td>0.66     </td><td>0.75  </td><td>3922    text-s&p raises ibm ratings \n",
       "Name: headline, dtype: object             </td><td>0                  </td><td>1                     </td></tr>\n",
       "<tr><td>RNN + CNN</td><td>0.7328  </td><td>0.65     </td><td>0.73  </td><td>3922    text-s&p raises ibm ratings \n",
       "Name: headline, dtype: object             </td><td>0                  </td><td>1                     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "example_2 = [[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"News Content\", \"Actual Stock Return\", \"Predicted Stock Return\"],\n",
    "            [\"RNN\", \"0.6906\", \"0.61\", \"0.69\", test['headline'][6:7], \"0\", \"0\"],\n",
    "            [\"CNN\", \"0.7445\", \"0.66\", \"0.75\", test['headline'][6:7], \"0\", \"1\"],\n",
    "            [\"RNN + CNN\", \"0.7328\", \"0.65\", \"0.73\", test['headline'][6:7], \"0\", \"1\"]\n",
    "    \n",
    "]\n",
    "\n",
    "display(HTML(tabulate.tabulate(example_2, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Model    </td><td>Accuracy</td><td>Precision</td><td>Recall</td><td>News Content</td><td>Actual Stock Return</td><td>Predicted Stock Return</td></tr>\n",
       "<tr><td>RNN      </td><td>0.6906  </td><td>0.61     </td><td>0.69  </td><td>1318    australia waves through news corp buy-in to struggling free-to-air ten \n",
       "Name: headline, dtype: object             </td><td>1                  </td><td>1                     </td></tr>\n",
       "<tr><td>CNN      </td><td>0.7445  </td><td>0.66     </td><td>0.75  </td><td>1318    australia waves through news corp buy-in to struggling free-to-air ten \n",
       "Name: headline, dtype: object             </td><td>1                  </td><td>0                     </td></tr>\n",
       "<tr><td>RNN + CNN</td><td>0.7328  </td><td>0.65     </td><td>0.73  </td><td>1318    australia waves through news corp buy-in to struggling free-to-air ten \n",
       "Name: headline, dtype: object             </td><td>1                  </td><td>0                     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "example_3 = [[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"News Content\", \"Actual Stock Return\", \"Predicted Stock Return\"],\n",
    "            [\"RNN\", \"0.6906\", \"0.61\", \"0.69\", test['headline'][5:6], \"1\", \"1\"],\n",
    "            [\"CNN\", \"0.7445\", \"0.66\", \"0.75\", test['headline'][5:6], \"1\", \"0\"],\n",
    "            [\"RNN + CNN\", \"0.7328\", \"0.65\", \"0.73\", test['headline'][5:6], \"1\", \"0\"]\n",
    "    \n",
    "]\n",
    "\n",
    "display(HTML(tabulate.tabulate(example_3, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
